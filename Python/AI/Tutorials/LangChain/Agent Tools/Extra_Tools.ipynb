{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain import LLMMathChain, SerpAPIWrapper\n",
    "from langchain.tools import Tool\n",
    "from langchain.agents import (\n",
    "    AgentType,\n",
    "    initialize_agent\n",
    ")\n",
    "\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm = ChatOpenAI(\n",
    "    model_name = \"gpt-3.5-turbo\",\n",
    "    temperature = 0,\n",
    "    openai_api_key = open(\"openai_api.txt\", \"r\").read()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need for Extra Tools\n",
    "\n",
    "Using agents allows us to give LLMs access to `tools`. These tools present an infinite number of possibilities. With tools, LLMs can search the web, do math, run code, and more.\n",
    "\n",
    "Althoug LangChains pre-build tools, in may `real-world` projects we'll often find that only so many requirements can be satisfied by existing tools. Thus we must modify existing tools or even build entirely new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Tools\n",
    "\n",
    "At their core, tools are objects that consume some `input`, typically in the format of a string (text), and `output` some helpful information as a string.\n",
    "\n",
    "In reality, they are little more than a simple function that we'd find in any code. The only `difference` is that `tools` take input from an LLM and feed their output to an LLM.\n",
    "\n",
    "Besides the actual function that is called a `Tool` consists of several components:\n",
    "* **name** (str, required) - the unique name of the tool.\n",
    "* **description** (str, optional-recommended) - determines the tool usage.\n",
    "* **return_direct** (bool, default-False) - stopes execution and return Tool Observation\n",
    "* **args_schema** (Pydantic BaseModel, optional-recommended) - used to provide more information (e.g. , few-shot examples) or validation for expected parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the First Tool\n",
    "\n",
    "search = SerpAPIWrapper(serpapi_api_key=open(\"serpapi_api.txt\").read())\n",
    "\n",
    "tools = [\n",
    "    Tool.from_function(\n",
    "        func = search.run,\n",
    "        name = \"Search\",\n",
    "        description = \"useful for when you need to answer questions about current events\"\n",
    "        # coroutine = ... <- you can specify an async method if desired as well\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the Second Tool\n",
    "\n",
    "llm_math_chain = LLMMathChain.from_llm(llm=chat_llm, verbose=True)\n",
    "\n",
    "class CalculatorInput(BaseModel):\n",
    "    question: str = Field()\n",
    "\n",
    "\n",
    "tools.append(\n",
    "    Tool.from_function(\n",
    "        func = llm_math_chain.run,\n",
    "        name = \"Calculator\",\n",
    "        description = \"useful for when you need to answer questions about math\",\n",
    "        args_schema = CalculatorInput\n",
    "        # coroutine= ... <- you can specify an async method if desired as well (the asynchronous version of the function)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initializing the Agent\n",
    "\n",
    "agent = initialize_agent(\n",
    "    agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    tools = tools,\n",
    "    llm = chat_llm,\n",
    "    verbose = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"Who is Leo DiCaprio's girlfriend? What is her current age raised to the 0.43 power?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
