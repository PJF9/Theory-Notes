{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, LLMMathChain\n",
    "from langchain.agents import (\n",
    "    get_all_tool_names,\n",
    "    load_tools,\n",
    "    Tool,\n",
    "    initialize_agent\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"openai_api.txt\", \"r\") as f:\n",
    "    OPENAI_API = f.read()\n",
    "\n",
    "llm = OpenAI(\n",
    "    model_name = \"gpt-3.5-turbo-instruct\",\n",
    "    temperature = 0,\n",
    "    openai_api_key = OPENAI_API\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Need of Agents\n",
    "\n",
    "Some applications require not just a predetermined chain of calls to LLM, but potentially an `unknown chain` that depends on the user's input. In these type of chains, there is an `agent` which has access to a suite of `tools`. Thus depending on the user's input, the agent then decides which, if any, of these tools to call.\n",
    "\n",
    "There are two main types of agents:\n",
    "1. **Action Agents** - agents that decides the actions to take and execute those, one at a time.\n",
    "2. **Plan-and-Execute Agents** - agents that decides a plan of actions to take, and execute those one at a time.\n",
    "\n",
    "`Action Agents` are more conventional, and good for small tasks. For more complex tasks, or long running tasks, the initial planning steps helps to maintain long term objectives and focus, thus `Plan-and-Execute Agents` are more suitable. However that comes of generally more calls and highet latency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Action Agents\n",
    "\n",
    "High level pseudocode of Action Agents:\n",
    "1. `Receive` User input.\n",
    "2. `Decide` which **tool** to use, if any, and what the **tool input** should be.\n",
    "3. `Call` the **tool** with the **tool input**, and `record` an **observation** (the output of this calling).\n",
    "4. `Decide` the next step according the **tool**, **tool input** and **observation**.\n",
    "\n",
    "-\n",
    "\n",
    "To better understand Agents let's see the abstraction that are involed:\n",
    "* `Agents`: An interface that takes in user input along side with a list of previous steps, apply \"logic\" and return either an AgentAction or AgentFinish.\n",
    "    * `AgentAction` - it's a dataclass that represents the action an agent should take. It has a tool property (which is the name of the tool that should be invoked) and a tool_input property (the input to that tool)\n",
    "    * `AgentFinish` - it's a dataclass that signifies that the agent has finished and should return to the user. It has a return_values parameter, which is a dictionary to return. It often only has one key - output - that is a string, and so often it is just this key that is returned\n",
    "\n",
    "* `Tools`: They're functions that an agent calls. There are two important considerations here:\n",
    "    1. Giving the agent access to the right tools\n",
    "    2. Describing the tools in a way that is most helpful to the agent\n",
    "\n",
    "* `Toolkits`: Often the set of tools an agent has access to is more important than a single tool. For this LangChain provides the concept of toolkits - groups of tools needed to accomplish specific objectives. There are generally around 3-5 tools in a toolkit.\n",
    "\n",
    "* `Agent Executor`: The agent executor is the runtime for an agent. This is what actually calls the agent and executes the actions it chooses. Pseudocode for this runtime is below:\n",
    "```\n",
    "next_action = agent.get_action(...)\n",
    "while next_action != AgentFinish:\n",
    "    observation = run(next_action)\n",
    "    next_action = agent.get_action(..., next_action, observation)\n",
    "return next_action\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agents\n",
    "\n",
    "In order to load agents, we should understand the following concepts:\n",
    "1. `Tool`: A function, a Chain or even another agent, that performs a specific duty, such as Google Search, Database lookup, etc.\n",
    "2. `LLM`: The language model powering the agent.\n",
    "3. `Agent`: The type of agent to use.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## The Calculator Tool\n",
    "# When initializing tools, we either create a custom tool or load a pre-built tool. In either cases the `tool` is a `utility chain` with a `name` and `description`\n",
    "\n",
    "# Initializing the Math Chain (we should pass an LLM Chain instead of an LLM)\n",
    "llm_math = LLMMathChain.from_llm(llm=llm)\n",
    "\n",
    "# Initializing the Custom Tool\n",
    "math_tool = Tool(\n",
    "    name = \"Calculator\",\n",
    "    description = \"Useful for math questions.\",\n",
    "    func = llm_math.run\n",
    ")\n",
    "\n",
    "# When passing tools to LLM we should pass them as List\n",
    "tools = [math_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools[0].name, tools[0].description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can see all tools available using:\n",
    "\n",
    "get_all_tool_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Loading a tool\n",
    "\n",
    "tools = load_tools(\n",
    "    tool_names = [\"llm-math\"],\n",
    "    llm = llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools[0].name, tools[0].description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have the LLM and tools but no agent. To initialize a simple agent, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_agent = initialize_agent(\n",
    "    agent = \"zero-shot-react-description\", # the type of the agent\n",
    "    tools = tools,\n",
    "    llm = llm,\n",
    "    verbose = True, # for printing what model is performing each query\n",
    "    max_iterations = 3\n",
    ")\n",
    "\n",
    "## Available Agent types can be found on `langchain.agents.agent_types.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Zero-shot` means the agent functions on the current action only — it has `no memory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Using the Agent\n",
    "\n",
    "zero_shot_agent(\"what is (4.5*2.1)^2.2?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(4.5*2.1)**2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_agent(\"if Mary has four apples and Giorgio brings two and a half apple \"\n",
    "                \"boxes (apple box contains eight apples), how many apples do we \"\n",
    "                \"have?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_agent(\"what is the capital of Greece?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run into an error. The problem here is that the agent keeps trying to use a tool. Yet, our agent contains only one tool — the calculator. So by giving the `Agent` more `Tools` we can solve this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting Prompt Template and LLM Chain\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = \"{query}\",\n",
    "    input_variables = [\"query\"]\n",
    ")\n",
    "\n",
    "llm_chain = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Initializing the LLM Tool\n",
    "\n",
    "llm_tool = Tool(\n",
    "    name = \"Language Model\",\n",
    "    description = \"Use this tool for general purpose queries and logic.\",\n",
    "    func = llm_chain.run\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding the Tool above to `tools`\n",
    "\n",
    "tools.append(llm_tool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reinitializing the Agent\n",
    "\n",
    "zero_shot_agent = initialize_agent(\n",
    "    agent = \"zero-shot-react-description\",\n",
    "    tools = tools,\n",
    "    llm = llm,\n",
    "    verbose = True,\n",
    "    max_iteations = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_agent(\"what is (4.5*2.1)^2.2?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_agent(\"if Mary has four apples and Giorgio brings two and a half apple \"\n",
    "                \"boxes (apple box contains eight apples), how many apples do we \"\n",
    "                \"have?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_shot_agent(\"what is the capital of Greece?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format of 'reasoning' is the following:\n",
    "* `Question` - the input question you must answer\n",
    "* `Thought` - the LLM should always think about what to do\n",
    "* `Action` - take action using one of the tools\n",
    "* `Action Input` - the input to the action\n",
    "* `Observation` - the result of the action\n",
    "* `Repeat` - repeat thought/action/action input/observation until reaches a result\n",
    "* `Thought` - now know the final answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(zero_shot_agent.agent.llm_chain.prompt.template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These `tools` and the `thought process` separate agents from chains in LangChain.\n",
    "\n",
    "Whereas a `chain` defines an `immediate` input/output process, the logic of `agents` allows a `step-by-step` thought process. The advantage of this step-by-step process is that the LLM can work through multiple reasoning steps or tools to produce a better answer.\n",
    "\n",
    "-\n",
    "\n",
    "The final aspect we need to understand is `Thought:{agent_scratchpad}`.\n",
    "\n",
    "The `agent_scratchpad` is where we add every thought or action the agent has already performed. All thoughts and actions (within the current agent executor chain) can then be accessed by the next thought-action-observation loop, enabling continuity in agent actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
