{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80BYZmIcft3B"
      },
      "outputs": [],
      "source": [
        "from langchain import OpenAI\n",
        "from langchain.agents import (\n",
        "    load_tools,\n",
        "    initialize_agent,\n",
        "    AgentType\n",
        ")\n",
        "from langchain.callbacks.streaming_stdout_final_only import FinalStreamingStdOutCallbackHandler\n",
        "from langchain.callbacks.base import BaseCallbackHandler\n",
        "\n",
        "import tiktoken\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1q21U2MJXa7"
      },
      "source": [
        "## Streaming Final Agent Output\n",
        "\n",
        "If you only want the final output of an agent to be streamed, you can use the callback `FinalStreamingStdOutCallbackHandler`. For this, the underlying LLM has to support streaming as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S6LoJOUrQMUM"
      },
      "outputs": [],
      "source": [
        "def get_tokens(input: str) -> List[str]:\n",
        "    tokens = []\n",
        "    enc_dec = tiktoken.get_encoding(\"p50k_base\")\n",
        "\n",
        "    for idx in enc_dec.encode(input):\n",
        "        tokens.append(str(enc_dec.decode_single_token_bytes(idx))[2:-1])\n",
        "\n",
        "    return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K_ROFd6NMMG6"
      },
      "outputs": [],
      "source": [
        "llm = OpenAI(\n",
        "    streaming = True,\n",
        "    callbacks = [FinalStreamingStdOutCallbackHandler()],\n",
        "    temperature = 0,\n",
        "    openai_api_key = open(\"openai_api.txt\").read()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KrtBudqQMY8L",
        "outputId": "3f0393a4-0d57-468e-8c91-fc0627a7b0fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Konrad Adenauer became Chancellor of Germany in 1949, which was 74 years ago in 2023."
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Konrad Adenauer became Chancellor of Germany in 1949, which was 74 years ago in 2023.'"
            ]
          },
          "execution_count": 163,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
        "agent = initialize_agent(\n",
        "    tools = tools,\n",
        "    llm = llm,\n",
        "    agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose = False\n",
        ")\n",
        "\n",
        "agent.run(\"It's 2023 now. How many years ago did Konrad Adenauer become Chancellor of Germany.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XQ2TS0vAMnPj"
      },
      "source": [
        "By default we assume that the token sequence \"Final\", \"Answer\", \":\" indicates that the agent has reached an answers. We can, however, also pass a custom sequence to use as answer prefix:\n",
        "```\n",
        "answer_prefix_tokens=[\"The\", \"answer\", \":\"]\n",
        "```\n",
        "\n",
        "For convenience, the callback automatically strips whitespaces and new line characters when comparing to answer_prefix_tokens. I.e., if answer_prefix_tokens = [\"The\", \" answer\", \":\"] then both [\"\\nThe\", \" answer\", \":\"] and [\"The\", \" answer\", \":\"] would be recognized a the answer prefix.\n",
        "\n",
        "-\n",
        "\n",
        "If you don't know the tokenized version of your answer prefix, you can determine it with the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kb1DzCOfMf7W",
        "outputId": "0ab4cc64-3bd6-4503-b2cf-3901caa46e26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "# I#\n",
            "# need#\n",
            "# to#\n",
            "# find#\n",
            "# out#\n",
            "# when#\n",
            "# Kon#\n",
            "#rad#\n",
            "# Aden#\n",
            "#auer#\n",
            "# became#\n",
            "# Chancellor#\n",
            "# of#\n",
            "# Germany#\n",
            "#.#\n",
            "#\n",
            "Action#\n",
            "#:#\n",
            "# Wikipedia#\n",
            "#\n",
            "Action#\n",
            "# Input#\n",
            "#:#\n",
            "# Kon#\n",
            "#rad#\n",
            "# Aden#\n",
            "#auer#\n",
            "##\n",
            "# I#\n",
            "# now#\n",
            "# know#\n",
            "# the#\n",
            "# date#\n",
            "# Kon#\n",
            "#rad#\n",
            "# Aden#\n",
            "#auer#\n",
            "# became#\n",
            "# Chancellor#\n",
            "# of#\n",
            "# Germany#\n",
            "#.#\n",
            "#\n",
            "Final#\n",
            "# Answer#\n",
            "#:#\n",
            "# Kon#\n",
            "#rad#\n",
            "# Aden#\n",
            "#auer#\n",
            "# became#\n",
            "# Chancellor#\n",
            "# of#\n",
            "# Germany#\n",
            "# in#\n",
            "# 1949#\n",
            "#,#\n",
            "# which#\n",
            "# was#\n",
            "# 74 years#\n",
            "# ago#\n",
            "# in#\n",
            "# 20#\n",
            "#23#\n",
            "#.#\n",
            "##\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Konrad Adenauer became Chancellor of Germany in 1949, which was 74 years ago in 2023.'"
            ]
          },
          "execution_count": 165,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class MyCallbackHandler(BaseCallbackHandler):\n",
        "    def on_llm_new_token(self, token, **kwargs) -> None:\n",
        "        # print every token on a new line\n",
        "        print(f\"#{token}#\")\n",
        "\n",
        "llm = OpenAI(\n",
        "    streaming = True,\n",
        "    callbacks = [MyCallbackHandler()],\n",
        "    temperature = 0,\n",
        "    openai_api_key = open(\"openai_api.txt\").read()\n",
        ")\n",
        "\n",
        "tools = load_tools([\"wikipedia\", \"llm-math\"], llm=llm)\n",
        "\n",
        "agent = initialize_agent(\n",
        "    tools = tools,\n",
        "    llm = llm,\n",
        "    agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=False\n",
        ")\n",
        "\n",
        "agent.run(\"It's 2023 now. How many years ago did Konrad Adenauer become Chancellor of Germany.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NTJaku_JNINn"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
