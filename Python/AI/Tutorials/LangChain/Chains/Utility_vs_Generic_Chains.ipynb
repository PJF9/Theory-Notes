{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import (\n",
    "    LLMChain,\n",
    "    LLMMathChain,\n",
    "    TransformChain,\n",
    "    SequentialChain\n",
    ")\n",
    "\n",
    "import re\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"openai_api.txt\", \"r\") as f:\n",
    "    OPENAI_API = f.read()\n",
    "\n",
    "llm = OpenAI(\n",
    "    model_name = \"gpt-3.5-turbo-instruct\",\n",
    "    openai_api_key = OPENAI_API\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chains\n",
    "\n",
    "Chains are the core of LangChain. They are simply a chain of components, executed in a `particular order`.\n",
    "\n",
    "The simplest of these chains is the `LLMChain` that works by taking a user's input, passing it to the first element of the Chain, i.e., a PromptTemplate and then this prompt into an LLM.\n",
    "\n",
    "By definition: _A chain is made up of links, which can be either primitives or other chains. Premitives can be either prompts, llms, utils or other chains_.\n",
    "\n",
    "Chains are divided in three types: `Utility`, `Generic` and `Combine Documents` chains.\n",
    "\n",
    "* `Utility` chains -- usually used to extract a specific answer from a llm with a very narrow purpose and are ready to be used out of the box.\n",
    "\n",
    "* `Generic` chains -- used as building blocks for other chains but cannot be used out of the box on their own."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Utility Chains`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_math = LLMMathChain(llm=llm, verbose=True)\n",
    "\n",
    "llm_math(\"What is 13 raised to the .3432 power?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(llm_math.prompt.template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Printing the chain's `__call__()` method:\n",
    "\n",
    "print(inspect.getsource(llm_math._call))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Either returns an answer or it returns a Python code which we compile for an exacr answer to harder problems\n",
    "\n",
    "* We get our first example of `chain composition`. We are using the *LLMMathChain* which in turn initializes and uses an *LLMChain* (a `Generic Chain`) when called.\n",
    "\n",
    "* `Utility chains` usually follow this same basic structure: there is a prompt for constraining the llm to return a very specific type of response from a given query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Generic Chains`\n",
    "\n",
    "We will build a custom transform function to clean the spacing of our texts. We will then use this function to build a chain where we input our text and we expect a clean text as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_func(inputs: dict) -> dict:\n",
    "    text = inputs[\"text\"]\n",
    "\n",
    "    # replace multiple new lines and multiple spaces with a single one\n",
    "    text = re.sub(r'(\\r\\n|\\r|\\n){2,}', r'\\n', text)\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "\n",
    "    return {\"output_text\": text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the Text Transformation Chain\n",
    "\n",
    "clean_extra_spaces_chain = TransformChain(\n",
    "    input_variables = [\"text\"],\n",
    "    output_variables = [\"output_text\"],\n",
    "    transform = transform_func\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_extra_spaces_chain.run('A random text  with   some irregular spacing.\\n\\n\\n     Another one   here as well.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating a Prompt Template to Pass it on Our Chain\n",
    "\n",
    "template = \"\"\"Paraphrase this text:\n",
    "{output_text}\n",
    "\n",
    "In the style of a {style}.\n",
    "\n",
    "Paraphrase: \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template = template,\n",
    "    input_variables = [\"output_text\", \"style\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating Base LLMChain object\n",
    "\n",
    "style_paraphrase_chain = LLMChain(\n",
    "    llm = llm,\n",
    "    prompt = prompt,\n",
    "    output_key = \"final_output\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Passing the Output of TransformChain into LLMChain\n",
    "\n",
    "sequential_chain = SequentialChain(\n",
    "    chains = [clean_extra_spaces_chain, style_paraphrase_chain],\n",
    "    input_variables = [\"text\", \"style\"],\n",
    "    output_variables = [\"final_output\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"\"\"\n",
    "Chains allow us to combine multiple\n",
    "\n",
    "components together to create a single, coherent application.\n",
    "\n",
    "For example, we can create a chain that takes user input,       format it with a PromptTemplate,\n",
    "\n",
    "and then passes the formatted response to an LLM. We can build more complex chains by combining     multiple chains together, or by\n",
    "\n",
    "\n",
    "combining chains with other components.\n",
    "\"\"\"\n",
    "\n",
    "print(sequential_chain({'text': input_text, 'style': 'a 90s rapper'})[\"final_output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
