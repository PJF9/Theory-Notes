{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "twdUgJ3cKKji"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.output_parsers import PydanticOutputParser, OutputFixingParser, RetryOutputParser, RetryWithErrorOutputParser\n",
        "\n",
        "from pydantic import BaseModel, Field, validator\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setting the LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "DYSkcuDLKOOj"
      },
      "outputs": [],
      "source": [
        "with open(\"openai_api.txt\", \"r\") as f:\n",
        "    OPENAI_API = f.read()\n",
        "\n",
        "llm = OpenAI(\n",
        "    model_name = \"gpt-3.5-turbo-instruct\",\n",
        "    temperature = 1.1,\n",
        "    openai_api_key = OPENAI_API\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbuE7PWCJbaa"
      },
      "source": [
        "## What are Output Parsers\n",
        "\n",
        "Language models output text. But many times you may want to get more structured information than just text back. This is where `output parsers` come in.\n",
        "\n",
        "Output parsers are classes that help structure language model responses. There are two main methods an output parser must implement:\n",
        "* **get_format_instructions() -> str**: A method which returns a string containing instructions for how the output of a language model should be formatted.\n",
        "\n",
        "* **parse(str) -> Any**: A method which takes in a string (assumed to be the response from a language model) and parses it into some structure.\n",
        "\n",
        "And then one optional one:\n",
        "* **parse_with_prompt(str) -> Any**: A method which takes in a string (assumed to be the response from a language model) and a prompt (assumed to the prompt that generated such a response) and parses it into some structure. The prompt is largely provided in the event the OutputParser wants to retry or fix the output in some way, and needs information from the prompt to do so.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "nQurtK7SMbC7"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Different Type of Output Parsers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AtWSxPt6MYeL"
      },
      "source": [
        "### `PydanticOutputParser`\n",
        "\n",
        "This output parser allows users to specify an arbitrary `JSON schema` and query LLMs for JSON outputs that conform to that schema.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "H2VdwvSBJV4h"
      },
      "outputs": [],
      "source": [
        "## Define the Desire Structure\n",
        "\n",
        "class Joke_Structure(BaseModel):\n",
        "    # Setting the `input variables`\n",
        "    setup: str = Field(description = \"question to set up a joke\")\n",
        "    punchline: str = Field(description = \"answer to resolve the joke\")\n",
        "\n",
        "    # Adding custom validating logit\n",
        "    @validator(\"setup\")\n",
        "    def question_ends_with_question_mark(cls, field):\n",
        "        if field[-1] != '?':\n",
        "            raise ValueError(\"Badly formed question!\")\n",
        "        return field"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "scYbp-i4K4tW"
      },
      "outputs": [],
      "source": [
        "## Initializing the Parser\n",
        "\n",
        "parser = PydanticOutputParser(pydantic_object = Joke_Structure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTvvbD_6LAqt",
        "outputId": "45baad02-2443-4d84-cec7-567b5873a6f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "('input_variables', ['query'])\n",
            "('output_parser', None)\n",
            "('partial_variables', {'format_instructions': 'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"setup\": {\"title\": \"Setup\", \"description\": \"question to set up a joke\", \"type\": \"string\"}, \"punchline\": {\"title\": \"Punchline\", \"description\": \"answer to resolve the joke\", \"type\": \"string\"}}, \"required\": [\"setup\", \"punchline\"]}\\n```'})\n",
            "('template', 'Answer the user query.\\n{format_instructions}\\n{query}\\n')\n",
            "('template_format', 'f-string')\n",
            "('validate_template', True)\n"
          ]
        }
      ],
      "source": [
        "## Setting Prompt Template\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template = \"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
        "    input_variables = [\"query\"],\n",
        "    partial_variables = {\"format_instructions\": parser.get_format_instructions()}\n",
        ")\n",
        "\n",
        "for k in prompt:\n",
        "    print(k)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ERGDLcstLbiR",
        "outputId": "d81283f1-fa8e-4d6c-ca30-c44281a5aa8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Answer the user query.\n",
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"setup\": {\"title\": \"Setup\", \"description\": \"question to set up a joke\", \"type\": \"string\"}, \"punchline\": {\"title\": \"Punchline\", \"description\": \"answer to resolve the joke\", \"type\": \"string\"}}, \"required\": [\"setup\", \"punchline\"]}\n",
            "```\n",
            "Tell me a joke.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "joke_query = \"Tell me a joke.\"\n",
        "\n",
        "_input = prompt.format_prompt(query=joke_query)\n",
        "\n",
        "print(_input.text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "-25WkRupL3GQ",
        "outputId": "982e2dc0-390d-41c2-c471-27b3906c4ab8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\n{\"setup\": \"Why did the chicken go to the séance?\", \"punchline\": \"To get to the other side!\"}'"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output = llm(_input.to_string())\n",
        "\n",
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q1IaJW1L47G",
        "outputId": "20012e6a-c634-4adf-c133-76f36da82593"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Joke_Structure(setup='Why did the chicken go to the séance?', punchline='To get to the other side!')"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "parser.parse(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "o8vDZ69DMKg8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YpEVegA_Mb6i"
      },
      "source": [
        "### `OutputFixingParser`\n",
        "\n",
        "This output parser wraps another output parser and tries to `fix` any mistakes.\n",
        "\n",
        "The `Pydantic` guardrail simply tries to parse the LLM response. If it does not parse correctly, then it `errors`.\n",
        "\n",
        "But we can do other things besides throw errors. Specifically, we can pass the misformatted output, along with the formatted instructions, to the model and ask it to fix it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "-4mNpen4MdVU"
      },
      "outputs": [],
      "source": [
        "## Let's get an Error\n",
        "\n",
        "class Actor(BaseModel):\n",
        "    name: str = Field(description = \"name of an actor\")\n",
        "    film_names: List[str] = Field(description = \"list of names of films they starred in\")\n",
        "        \n",
        "parser = PydanticOutputParser(pydantic_object=Actor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8n6HM9KNECs",
        "outputId": "a98fe0ac-7f83-458b-fa03-91951f220439"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error...\n"
          ]
        }
      ],
      "source": [
        "misformatted = \"{'name': 'Tom Hanks', 'film_names': ['Forrest Gump']}\"\n",
        "\n",
        "try:\n",
        "    parser.parse(misformatted)\n",
        "except ValueError:\n",
        "    print(\"Error...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ug2SlsYGNHTD",
        "outputId": "b4b2a6a4-79d3-4529-b09b-c33d236986d2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Actor(name='Tom Hanks', film_names=['Forrest Gump'])"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Fixing the Misformatted Problem\n",
        "\n",
        "new_parser = OutputFixingParser.from_llm(parser=parser, llm=llm)\n",
        "\n",
        "new_parser.parse(misformatted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJLt1DrwNZLB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85gyvcDLN5tI"
      },
      "source": [
        "### `RetryOutputParser`\n",
        "\n",
        "While in some cases it is possible to fix any parsing mistakes by only looking at the output, in other cases we can't."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lScZfk7qOAks",
        "outputId": "a04a82e3-37b8-43b8-e099-166efa8bd727"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error...\n"
          ]
        }
      ],
      "source": [
        "## Getting an Error\n",
        "\n",
        "class Action(BaseModel):\n",
        "    action: str = Field(description = \"action to take\")\n",
        "    action_input: str = Field(description = \"input to the action\")\n",
        "        \n",
        "parser = PydanticOutputParser(pydantic_object=Action)\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    template = \"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
        "    input_variables = [\"query\"],\n",
        "    partial_variables = {\"format_instructions\": parser.get_format_instructions()}\n",
        ")\n",
        "\n",
        "prompt_value = prompt.format_prompt(query=\"who is leo di caprios gf?\")\n",
        "\n",
        "bad_response = '{\"action\": \"search\"}'\n",
        "\n",
        "try:\n",
        "    parser.parse(bad_response)\n",
        "except ValueError:\n",
        "    print(\"Error...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Sa2qVpcOjDO",
        "outputId": "ff37118f-f917-4661-f0e3-7c60493d55b4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Action(action='search', action_input='term')"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Fixing the Error\n",
        "\n",
        "fix_parser = RetryOutputParser.from_llm(parser=parser, llm=llm)\n",
        "\n",
        "fix_parser.parse(bad_response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EW0cu-W8O5xd"
      },
      "source": [
        "We can see that although the error resolved, the model is confused and doesn't know what to put for action input."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OiR7wT9UOpGu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T17GGdl5Oyvu"
      },
      "source": [
        "### `RetryWithErrorOutputParser`\n",
        "\n",
        "We can use the RetryWithErrorOutputParser, which passes in the prompt (as well as the original output) to try again to get a better response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8W9uhpHKO3JH",
        "outputId": "3bb0d47d-07b4-4bcd-a06d-d44df368a1f7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Action(action='search', action_input='who is leo di caprios gf?')"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retry_parser = RetryWithErrorOutputParser.from_llm(parser=parser, llm=llm)\n",
        "\n",
        "retry_parser.parse_with_prompt(bad_response, prompt_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m-rB4SpbPGzr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
