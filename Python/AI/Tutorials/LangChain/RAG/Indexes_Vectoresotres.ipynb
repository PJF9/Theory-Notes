{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {
        "id": "igK8myqMarXW"
      },
      "outputs": [],
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.document_loaders import TextLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.schema import Document\n",
        "\n",
        "from abc import ABC, abstractmethod\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZSiRVRbao4l"
      },
      "source": [
        "## What are Indexes\n",
        "\n",
        "Indexes refer to ways to structure `documents` so that LLMs can best interact with them. The most common way that indexes are used in chains is in a `retrieval` step. This step refers to taking a user's query and returning the most relevant documents.\n",
        "\n",
        "Most of the time when we talk about indexes and retrieval we are talking about indexing and retrieving `unstructured data`. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Eackqfg6aitU"
      },
      "outputs": [],
      "source": [
        "## The `BaseRetriever` interface is as simple as the following class\n",
        "\n",
        "class BaseRetriever(ABC):\n",
        "    @abstractmethod\n",
        "    def get_relevant_documents(self, query: str) -> List[Document]:\n",
        "        \"\"\"Get texts relevant for a query.\n",
        "\n",
        "        Args:\n",
        "            query: string to find relevant texts for\n",
        "\n",
        "        Returns:\n",
        "            List of relevant documents\n",
        "        \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uebqtw_sbnQr"
      },
      "source": [
        "where the `get_relevant_documents` method can be implemented as we like.\n",
        "\n",
        "The main type of Retriever is a `Vectorstore` retriever. In order to understand what this type of retriever is, we need to discuss more about Vectorstores. To showcase Vectorstores we are going to create a simple `question answering` system in a document.\n",
        "\n",
        "QA over a document consist of those steps:\n",
        "1. Create an `Index`.\n",
        "2. Create a `Retriever` from that Index.\n",
        "3. Create a QA `Chain`.\n",
        "4. `Ask` Questions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_7ns9eRblIg",
        "outputId": "8e66e798-bea2-439c-fb2b-1f29b16cd401"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langchain.document_loaders.text.TextLoader at 0x7f06703e7f40>"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Loading the document into LangChain\n",
        "\n",
        "loader = TextLoader(\"state_of_the_union.txt\", encoding=\"utf-8\")\n",
        "loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I2YYlQzae93q",
        "outputId": "a199cd0b-81c4-4332-ac47-4652a14d0506"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(list, langchain.schema.Document)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Splitting Text into Chunks\n",
        "\n",
        "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
        "texts = text_splitter.split_documents(loader.load())\n",
        "\n",
        "type(texts), type(texts[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "9VmntaQNdQXF"
      },
      "outputs": [],
      "source": [
        "## Setting an Embedding Model\n",
        "\n",
        "embeddings = OpenAIEmbeddings(openai_api_key=open(\"openai_api.txt\").read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YJtZrTGcfOvZ",
        "outputId": "9b5b430b-9ac5-4452-f159-5e62a7d875b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<langchain.vectorstores.chroma.Chroma at 0x7f06767dbaf0>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Creating a Vectorestore using an Index\n",
        "\n",
        "db = Chroma.from_documents(texts, embeddings)\n",
        "db"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Perfroming Queries\n",
        "\n",
        "query = \"What is Advengers\"\n",
        "docs = db.similarity_search(query, k=2)\n",
        "docs[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Adding text to the Vectorstore\n",
        "\n",
        "db.add_texts([\"Ankush went to Princeton College\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "query = \"Where did Ankush go to college?\"\n",
        "docs = db.similarity_search(query)\n",
        "\n",
        "docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You can see more about `Vectorestores` here: https://python.langchain.com/docs/modules/data_connection/vectorstores/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HgIs0QDflXz",
        "outputId": "b5e9cfd1-eb03-4cc1-cbe9-f458a64d575b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "VectorStoreRetriever(vectorstore=<langchain.vectorstores.chroma.Chroma object at 0x7f06767dbaf0>, search_type='similarity', search_kwargs={})"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Creating a Retriever from that Index\n",
        "\n",
        "retriever = db.as_retriever()\n",
        "retriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "7DcDlJ-Ifwsc"
      },
      "outputs": [],
      "source": [
        "## Creating the QA Chain\n",
        "\n",
        "qa = RetrievalQA.from_chain_type(llm=OpenAI(openai_api_key=open(\"openai_api.txt\").read()), chain_type=\"stuff\", retriever=retriever)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VKhtkoDvf-Lm",
        "outputId": "e3913ada-3640-48d0-df97-38a6c37caa1b"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\" The president said that Ketanji Brown Jackson is one of the nation's top legal minds and will continue Justice Breyer's legacy of excellence.\""
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "## Asking Questions\n",
        "\n",
        "query = \"What did the president say about Ketanji Brown Jackson\"\n",
        "qa.run(query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "8bncx9t7gDmq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "J7QWdzbBinwk",
        "nxl9k-LPi3kj",
        "kmxeUda5jREb",
        "03OBQfudlhzW",
        "jRvHSaLgmwiF",
        "xtr8NUkdoyu_",
        "WlvtyX6fpZd-",
        "DJFiIyB_quO9"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
