{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g40fuswu07zx",
        "outputId": "35d41deb-efee-4eb9-aa2e-558a8d5a8ca9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.65.0)\n",
            "Collecting aiohttp (from openai)\n",
            "  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting multidict<7.0,>=4.5 (from aiohttp->openai)\n",
            "  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp->openai)\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting yarl<2.0,>=1.0 (from aiohttp->openai)\n",
            "  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp->openai)\n",
            "  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp->openai)\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.6 yarl-1.9.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai"
      ],
      "metadata": {
        "id": "ezW-ag151L9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"api_key.txt\", \"r\") as f:\n",
        "    API_KEY = f.read()\n",
        "\n",
        "openai.api_key = API_KEY"
      ],
      "metadata": {
        "id": "rPoXqOYi09Ph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## How to Use the ChatGPT API\n",
        "\n",
        "The ChatGPT API is primarily optimized for chat but it also works well for text completion tasks. It consist of `gpt-3.5-turbo`, aka ChatGPT and `gpt-4` that are more powerful and cheaper than the previoys GPT-3 models.\n",
        "\n",
        "However, as of writing, you can not fine-tune the GPT-3.5 models. You can only fine-tune the GPT-3 base models i.e., *davinci*, *curie*, *ada*, and *cabbage*."
      ],
      "metadata": {
        "id": "XNqas5QA0VMK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfRzfqyB0Szs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the ChatGPT API for Chat Completion"
      ],
      "metadata": {
        "id": "R0_uZec505lA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completion = openai.ChatCompletion.create(\n",
        "    model = \"gpt-3.5-turbo\",\n",
        "    temperature = 0.8,\n",
        "    max_tokens = 2000,\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a funny comedian who tells dad jokes.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Write a dad joke related to numbers.\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Q: How do you make 7 even? A: Take away the s.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Write one related to programmers.\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jST9Vf231Pxo",
        "outputId": "839ac03b-1603-4abc-d578-4fed9552b008"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"content\": \"Q: Why do programmers prefer dark mode? A: Because light attracts bugs.\",\n",
            "  \"role\": \"assistant\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above code demonstrates a ChatGPT API call using Python. Note that the model was able to understand the context (\"dad joke\") and the type of response (Q&A form) that we were expecting even though we didn't explicitly mention it in the last user prompt.\n",
        "\n",
        "Thus, when building applications, you can provide the context in advance and the model will adapt to your requirements accordingly.\n",
        "\n",
        "Here, the most important part is the `messages` parameter which accepts an array of message objects. Each message object contains a `role` and `content`. You can provide three types of roles to the message objects:\n",
        "* `system`: It sets up the context and behavior of the assistant.\n",
        "* `user`: It's used to give instructions to the assistant. It is typically generated by the end user. But you as a developer can also provide some potential user prompts beforehand.\n",
        "* `assistant`: We provide the assistant with some information in advance so that it gives us the response we expect from the API.\n",
        "\n",
        "You can further customize the `temperature` and `max_tokens` parameters of the model to get the output according to your requirements. The higher the temperature, the higher the randomness of the output, and vice-versa. Finally the `gpt-3.5-turbo` model has a token limit of 4,096, while `gpt-4` has a limit of 8,192 tokens."
      ],
      "metadata": {
        "id": "7YGFPrCz2Va3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UqdcgY5RGbNb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Using the ChatGPT API for Text Completion"
      ],
      "metadata": {
        "id": "miVhTn8cGY6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completion = openai.ChatCompletion.create(\n",
        "    model = \"gpt-3.5-turbo\",\n",
        "    temperature = 0.8,\n",
        "    max_tokens = 2000,\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a poet who creates poems that evoke emotions.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Write a short poem for programmers.\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1C6foX2tGhJ7",
        "outputId": "1311d183-cf9a-4a5a-daf2-0ed53e81212c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lines of code form a dance,  \n",
            "Syntax and logic in a trance  \n",
            "Programmers create with precision  \n",
            "Their art, a digital vision  \n",
            "\n",
            "Brackets, semicolons, and more  \n",
            "A language that speaks to the core  \n",
            "Programmers weave a web of code  \n",
            "Innovations in every node  \n",
            "\n",
            "Their minds, a symphony of logic  \n",
            "A passion that's pure and iconic  \n",
            "For what they create, a world is born  \n",
            "A digital magic, forever adorned  \n",
            "\n",
            "So here's to the programmers,  \n",
            "Bringing life to machines with their slammers  \n",
            "May their code be bug-free and run  \n",
            "And their passion never be undone.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "btbKAyGVGlVE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building Applications Using the ChatGPT API\n",
        "\n",
        "You can directly use the `API` endpoint or the openai Python library to start building `ChatGPT` API-powered applications. Apart from the official openai library, you can also develop applications using the community-maintained libraries recommended by OpenAI."
      ],
      "metadata": {
        "id": "mntC94EBG2v-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method 1: Using the API Endpoint\n",
        "\n",
        "You need to use the /v1/chat/completions endpoint to utilize the gpt-3.5-turbo and gpt-4 models."
      ],
      "metadata": {
        "id": "h2HfiiANHHFJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "\n",
        "\n",
        "URL = \"https://api.openai.com/v1/chat/completions\"\n",
        "\n",
        "payload = {\n",
        "    \"model\": \"gpt-3.5-turbo\",\n",
        "    \"temperature\" : 1.0,\n",
        "    \"messages\" : [\n",
        "        {\"role\": \"system\", \"content\": f\"You are an assistant who tells any random and very short fun fact about this world.\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Write a fun fact about programmers.\"},\n",
        "        {\"role\": \"assistant\", \"content\": f\"Programmers drink a lot of coffee!\"},\n",
        "        {\"role\": \"user\", \"content\": f\"Write one related to the Python programming language.\"}\n",
        "    ]\n",
        "}\n",
        "\n",
        "headers = {\n",
        "    \"Content-Type\": \"application/json\",\n",
        "    \"Authorization\": f\"Bearer {openai.api_key}\"\n",
        "}\n",
        "\n",
        "response = requests.post(URL, headers=headers, json=payload)\n",
        "response = response.json()\n",
        "\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Fh9Q60XHKZo",
        "outputId": "56a6ad9e-f6be-433f-bd64-9efce4cedb9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python was named after Monty Python’s Flying Circus, a popular British sketch comedy show.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The above sample code demonstrates how you can directly use the endpoint to make the API call using the requests library."
      ],
      "metadata": {
        "id": "OkxRF7MZHmUq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Method 2: Using the Official openai Library"
      ],
      "metadata": {
        "id": "lxvsqapKHrtB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = openai.ChatCompletion.create(\n",
        "    model = \"gpt-3.5-turbo\",\n",
        "    temperature = 0.2,\n",
        "    max_tokens = 1000,\n",
        "    messages = [\n",
        "        {\"role\": \"user\", \"content\": \"Who won the 2018 FIFA world cup?\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3u-oPJs2HXi8",
        "outputId": "0508c979-50d1-4f68-ed5d-2b101a665d8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "France won the 2018 FIFA World Cup.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simulating Context using Multiple Assistants"
      ],
      "metadata": {
        "id": "_k27Qgz1MAb3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Example 1\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model = \"gpt-3.5-turbo\",\n",
        "    temperature = 0.2,\n",
        "    max_tokens = 1000,\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"Είσαι ένας καθηγητής πανεπιστημίου\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Έχεις εξηγήσει ήδη τις 4 αλληλεπιδράσεις της φυσικής\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Εχεις ήδη δώσει παράδειγμα για τη βαρυτική δύναμη\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Έχεις εξηγήσει σε βαθος την ισχυρή πυρινική\"},\n",
        "        {\"role\": \"user\", \"content\": \"Εξήγησέ μου ξανά παρακαλώ\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmdJFPqwHzRo",
        "outputId": "b1f93c42-2d16-455a-b0d7-36de0be389fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Η ισχυρή πυρηνική δύναμη είναι μία από τις τέσσερις βασικές δυνάμεις της φύσης, μαζί με τη βαρυτική, την ηλεκτρομαγνητική και την ασθενή πυρηνική δύναμη. Αυτή η δύναμη είναι υπεύθυνη για τη συγκράτηση των πυρήνων των ατόμων και τη δημιουργία των στοιχείων του ηλεκτρομαγνητικού φάσματος.\n",
            "\n",
            "Η ισχυρή πυρηνική δύναμη είναι μία πολύ ισχυρή δύναμη που δρα μόνο σε πολύ μικρές αποστάσεις, στο εσωτερικό του πυρήνα. Αυτή η δύναμη είναι τόσο ισχυρή που μπορεί να νικήσει την απωλεια μάζας που παρουσιάζεται κατά την αντίδραση δύο πυρήνων και να δημιουργήσει ενέργεια σε μορφή ακτινοβολίας και θερμότητας.\n",
            "\n",
            "Η ισχυρή πυρηνική δύναμη είναι επίσης υπεύθυνη για τη δημιουργία των πυρήνων των στοιχείων του ηλεκτρομαγνητικού φάσματος, όπως του υδρογόνου, του ήλιου και των άλλων αστέρων. Χωρίς αυτή τη δύναμη, δεν θα υπήρχαν τα στοιχεία που αποτελούν το σύμπαν μας.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example 2\n",
        "\n",
        "response = openai.ChatCompletion.create(\n",
        "    model = \"gpt-3.5-turbo\",\n",
        "    temperature = 0.2,\n",
        "    max_tokens = 1000,\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"Είσαι ένας καθηγητής πανεπιστημίου\"},\n",
        "        {\"role\": \"user\", \"content\": \"Ποιές είναι οι 4 αλληλεπιδράσεις στη φυσική;\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Έχεις εξηγήσει ποιές είναι οι 4 αλληλεπιδράσεις στη φυσική\"},\n",
        "        {\"role\": \"user\", \"content\": \"Δώσε μου ένα παράδειγμα για τη βαρυτική δύναμη\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Εχεις δώσει ένα παράδειγμα για τη βαρυτική δύναμη\"},\n",
        "        {\"role\": \"user\", \"content\": \"Μπορείς να μου σε βάθος την ασθενής πυρηνική αλληλεπίδραση;\"},\n",
        "        {\"role\": \"assistant\", \"content\": \"Έχεις εξηγήσει σε βαθος την ασθενή πυρινική δύναμη\"},\n",
        "        {\"role\": \"user\", \"content\": \"Εξήγησέ μου ξανά παρακαλώ\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(response[\"choices\"][0][\"message\"][\"content\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tfyzu8_EIGNf",
        "outputId": "1358e62e-3a9f-4278-96b6-d7d36696a233"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Η ασθενής πυρηνική δύναμη είναι μια από τις τέσσερις βασικές δυνάμεις της φύσης, που επιτρέπει τη συγκράτηση των πυρήνων των ατόμων. Αυτή η δύναμη είναι πολύ ισχυρή σε μικρές αποστάσεις, αλλά γρήγορα αποσβένεται με την αύξηση της απόστασης. Αυτό σημαίνει ότι η ασθενής πυρηνική δύναμη δρα μόνο στο εσωτερικό του πυρήνα και είναι υπεύθυνη για τη συγκράτηση των πρωτονίων και νετρονίων στον πυρήνα του ατόμου.\n",
            "\n",
            "Η ασθενής πυρηνική δύναμη είναι πολύ σημαντική για την κατανόηση της δομής του ατόμου και της σύνθεσης του πυρήνα. Χωρίς αυτή τη δύναμη, οι πρωτόνια και τα νετρόνια θα απομακρυνόντουσαν από τον πυρήνα και το ατομικό πυρήνα δεν θα μπορούσε να συγκρατηθεί. Η ασθενής πυρηνική δύναμη επίσης εξηγεί τη σταθερότητα των ισοτόπων και την απελευθέρωση ενέργειας κατά τη διάσπαση των βαρέων πυρήνων.\n"
          ]
        }
      ]
    }
  ]
}