{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn, optim\n",
        "\n",
        "import pandas as pd\n",
        "from os import cpu_count\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "AH88Jgh4S1GR"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Default Device"
      ],
      "metadata": {
        "id": "HxGajgyGuxLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device.type"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nH06egWiuyjW",
        "outputId": "2b8e25f2-3f16-4277-c500-1c78358966c7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading the Dataset"
      ],
      "metadata": {
        "id": "W0aVhg8xSwIa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXbH855cShzH",
        "outputId": "12df3c0d-9ec3-4a35-b4c2-c25ec31ad260"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Dataset `/content/reviews_Cell_Phones_and_Accessories_5.json` alerady exists...\n"
          ]
        }
      ],
      "source": [
        "# We have to unzip the dataset: 'reviews_Cell_Phones_and_Accessories_5.json.gz'\n",
        "import gzip\n",
        "from pathlib import Path\n",
        "import shutil\n",
        "\n",
        "# Setting the path of the zip file\n",
        "zip_path = Path(\"/content/reviews_Cell_Phones_and_Accessories_5.json.gz\")\n",
        "dest_path = Path(\"/content/reviews_Cell_Phones_and_Accessories_5.json\")\n",
        "\n",
        "if not dest_path.is_file():\n",
        "    with gzip.open(zip_path, \"rb\") as zip_ref:\n",
        "        print(f\"[INFO] Unzipping dataset `{zip_path}` to `{dest_path}`...\")\n",
        "        with open(dest_path, \"wb\") as un_zip_ref:\n",
        "            shutil.copyfileobj(zip_ref, un_zip_ref)\n",
        "\n",
        "    print(f\"[INFO] Dataset succesfully downloaded to `{dest_path}`...\")\n",
        "else:\n",
        "    print(f\"[INFO] Dataset `{dest_path}` alerady exists...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Seeing the Dataset"
      ],
      "metadata": {
        "id": "o-aXgVv0UCZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_json(dest_path, lines=True)\n",
        "\n",
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "id": "g8DmXlsmUK9x",
        "outputId": "893515ef-c468-4acf-e52d-39607f0b1dda"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       reviewerID        asin reviewerName helpful  \\\n",
              "0  A30TL5EWN6DFXT  120401325X    christina  [0, 0]   \n",
              "1   ASY55RVNIL0UD  120401325X     emily l.  [0, 0]   \n",
              "2  A2TMXE2AFO7ONB  120401325X        Erica  [0, 0]   \n",
              "\n",
              "                                          reviewText  overall  \\\n",
              "0  They look good and stick good! I just don't li...        4   \n",
              "1  These stickers work like the review says they ...        5   \n",
              "2  These are awesome and make my phone look so st...        5   \n",
              "\n",
              "                 summary  unixReviewTime   reviewTime  \n",
              "0             Looks Good      1400630400  05 21, 2014  \n",
              "1  Really great product.      1389657600  01 14, 2014  \n",
              "2         LOVE LOVE LOVE      1403740800  06 26, 2014  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-343000f1-7d37-40d3-a08d-a26cdc690f89\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewerName</th>\n",
              "      <th>helpful</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "      <th>summary</th>\n",
              "      <th>unixReviewTime</th>\n",
              "      <th>reviewTime</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A30TL5EWN6DFXT</td>\n",
              "      <td>120401325X</td>\n",
              "      <td>christina</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>They look good and stick good! I just don't li...</td>\n",
              "      <td>4</td>\n",
              "      <td>Looks Good</td>\n",
              "      <td>1400630400</td>\n",
              "      <td>05 21, 2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ASY55RVNIL0UD</td>\n",
              "      <td>120401325X</td>\n",
              "      <td>emily l.</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>These stickers work like the review says they ...</td>\n",
              "      <td>5</td>\n",
              "      <td>Really great product.</td>\n",
              "      <td>1389657600</td>\n",
              "      <td>01 14, 2014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A2TMXE2AFO7ONB</td>\n",
              "      <td>120401325X</td>\n",
              "      <td>Erica</td>\n",
              "      <td>[0, 0]</td>\n",
              "      <td>These are awesome and make my phone look so st...</td>\n",
              "      <td>5</td>\n",
              "      <td>LOVE LOVE LOVE</td>\n",
              "      <td>1403740800</td>\n",
              "      <td>06 26, 2014</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-343000f1-7d37-40d3-a08d-a26cdc690f89')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-343000f1-7d37-40d3-a08d-a26cdc690f89 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-343000f1-7d37-40d3-a08d-a26cdc690f89');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess the Dataset"
      ],
      "metadata": {
        "id": "1qoRiUpGU3x1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ps = pd.Series(df[\"reviewText\"])\n",
        "\n",
        "ps[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "RwCl0OjiU2ot",
        "outputId": "2279cd7b-66bf-485a-a256-85c0116c1de0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"They look good and stick good! I just don't like the rounded shape because I was always bumping it and Siri kept popping up and it was irritating. I just won't buy a product like this again\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ps = ps[: len(ps) // 2]\n",
        "\n",
        "len(ps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXhZMnS57mhN",
        "outputId": "b9afb31f-666e-4f6f-c925-2f6752dabffb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "48609"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zero_length_revies_index = [i for i in range(len(ps)) if len(ps[i]) == 0]\n",
        "\n",
        "non_zero_ps = ps.drop(zero_length_revies_index)\n",
        "non_zero_ps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejsbiilcU_Ru",
        "outputId": "520f5f0e-9da2-4768-ab38-15580612bcc5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        They look good and stick good! I just don't li...\n",
              "1        These stickers work like the review says they ...\n",
              "2        These are awesome and make my phone look so st...\n",
              "3        Item arrived in great time and was in perfect ...\n",
              "4        awesome! stays on, and looks great. can be use...\n",
              "                               ...                        \n",
              "48604    This charger works but it doesn't charge the b...\n",
              "48605    This charger works very well once you understa...\n",
              "48606    This is a handy device as you can use it to ch...\n",
              "48607    I love this charger... it charges almost every...\n",
              "48608    Not sure what the additional 2 buttons are for...\n",
              "Name: reviewText, Length: 48579, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from string import punctuation\n",
        "\n",
        "\n",
        "def tokenize(sentence):\n",
        "    # Creating the lookup table to replace all punctuation with spaces (' ')\n",
        "    translation_dict = {i: ord(\" \") for i in [ord(x) for x in punctuation]}\n",
        "\n",
        "    # Replacing all punctuation with spaces\n",
        "    unpuctuate_sentence = sentence.translate(translation_dict)\n",
        "\n",
        "    # Creating the tokanization of the sentence\n",
        "    tokenized_list = [word.lower() for word in unpuctuate_sentence.split(\" \") if (len(word) > 1 or word == 'I')]\n",
        "\n",
        "    return tokenized_list"
      ],
      "metadata": {
        "id": "kVijMa9cYLnF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_ps = non_zero_ps.apply(tokenize)\n",
        "\n",
        "tokenized_ps"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6r_TWFREcMeN",
        "outputId": "fb1f9a2f-215e-48ad-edd9-dd011421b79b"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [they, look, good, and, stick, good, i, just, ...\n",
              "1        [these, stickers, work, like, the, review, say...\n",
              "2        [these, are, awesome, and, make, my, phone, lo...\n",
              "3        [item, arrived, in, great, time, and, was, in,...\n",
              "4        [awesome, stays, on, and, looks, great, can, b...\n",
              "                               ...                        \n",
              "48604    [this, charger, works, but, it, doesn, charge,...\n",
              "48605    [this, charger, works, very, well, once, you, ...\n",
              "48606    [this, is, handy, device, as, you, can, use, i...\n",
              "48607    [i, love, this, charger, it, charges, almost, ...\n",
              "48608    [not, sure, what, the, additional, buttons, ar...\n",
              "Name: reviewText, Length: 48579, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the Vocabulary"
      ],
      "metadata": {
        "id": "xZgBcZAtcvSM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# vocab = set()\n",
        "# for tokenized_sentence in tokenized_ps:\n",
        "#     for word in tokenized_sentence:\n",
        "#         vocab.add(word)\n",
        "\n",
        "# vocab = list(vocab)\n",
        "\n",
        "# The same code as above can be written (for performance increment)\n",
        "vocab = list(set(word for tokenized_sentence in tokenized_ps for word in tokenized_sentence))\n",
        "vocab_idx = {vocab[i] : i for i in range(len(vocab))}\n",
        "\n",
        "vocab_idx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oBxuaQyLcw0-",
        "outputId": "1f7877b3-1dff-49c0-b214-43719d367def"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mimics': 0,\n",
              " '16did': 1,\n",
              " 'cdma': 2,\n",
              " 'tradtional': 3,\n",
              " 'immediatly': 4,\n",
              " 'mishaps': 5,\n",
              " 'administrators': 6,\n",
              " 'san': 7,\n",
              " 'sosteni': 8,\n",
              " 'multifunctional': 9,\n",
              " 'originial': 10,\n",
              " 'trusty': 11,\n",
              " 'motoq': 12,\n",
              " 'gus': 13,\n",
              " 'smidgen': 14,\n",
              " 'swirly': 15,\n",
              " 'origins': 16,\n",
              " 'fetish': 17,\n",
              " 'fitmentcons': 18,\n",
              " 'naught': 19,\n",
              " 'audiothings': 20,\n",
              " 'bicyclist': 21,\n",
              " 'interlocutor': 22,\n",
              " 'cheapera': 23,\n",
              " 'muzac': 24,\n",
              " 'aobut': 25,\n",
              " 'downsides': 26,\n",
              " 'goers': 27,\n",
              " 'principal': 28,\n",
              " 'subside': 29,\n",
              " 'globalsat': 30,\n",
              " 'labeling': 31,\n",
              " 'vase': 32,\n",
              " 'echo': 33,\n",
              " 'facebooking': 34,\n",
              " 'qwest': 35,\n",
              " 'thumps': 36,\n",
              " 'chews': 37,\n",
              " 'excellentpowergen': 38,\n",
              " 'cleanest': 39,\n",
              " 'royally': 40,\n",
              " 'razrs': 41,\n",
              " 'amaizing': 42,\n",
              " 'soldiers': 43,\n",
              " 'qualitywe': 44,\n",
              " 'telemarketers': 45,\n",
              " 'compressing': 46,\n",
              " 'admire': 47,\n",
              " 'robustly': 48,\n",
              " 'kickbacks': 49,\n",
              " '6700mah': 50,\n",
              " 'snake': 51,\n",
              " 'utilizar': 52,\n",
              " 'knock': 53,\n",
              " 'system': 54,\n",
              " 'sudo': 55,\n",
              " 'comprehension': 56,\n",
              " 'impartial': 57,\n",
              " 'cumbersomegoogle': 58,\n",
              " 'routing': 59,\n",
              " 'problam': 60,\n",
              " 'bolder': 61,\n",
              " 'theory': 62,\n",
              " 'shell': 63,\n",
              " 'switchanother': 64,\n",
              " 'belkincons': 65,\n",
              " 'bacomes': 66,\n",
              " 'snn5893athis': 67,\n",
              " 'guaranteeing': 68,\n",
              " 'fizzing': 69,\n",
              " 'anachronistic': 70,\n",
              " 'jason': 71,\n",
              " 'annoyingthe': 72,\n",
              " 'attachments': 73,\n",
              " 'nicephone': 74,\n",
              " 'microsim': 75,\n",
              " '4460': 76,\n",
              " 'jack10': 77,\n",
              " 'vto': 78,\n",
              " 'sandwiched': 79,\n",
              " 'incipio': 80,\n",
              " 'replenishment': 81,\n",
              " 'fridge': 82,\n",
              " 'appearsin': 83,\n",
              " 'cougar': 84,\n",
              " 'blistered': 85,\n",
              " 'fairly': 86,\n",
              " 'lasik': 87,\n",
              " 'coopers': 88,\n",
              " 'groove': 89,\n",
              " 'jawbone': 90,\n",
              " 'definetively': 91,\n",
              " 'sute': 92,\n",
              " 'rc2': 93,\n",
              " 'socket2': 94,\n",
              " 'twc': 95,\n",
              " 'manafacturers': 96,\n",
              " 'feeding': 97,\n",
              " 'biggerhole': 98,\n",
              " 'clings': 99,\n",
              " 'emailer': 100,\n",
              " 'wirelessfinest': 101,\n",
              " 'viberate': 102,\n",
              " 'plethora': 103,\n",
              " 'toughcase': 104,\n",
              " 'evens': 105,\n",
              " 'thegoogle': 106,\n",
              " 'swiping': 107,\n",
              " 'sifted': 108,\n",
              " 'downclocking': 109,\n",
              " 'z515': 110,\n",
              " 'kraken': 111,\n",
              " 'teeth': 112,\n",
              " 'vert': 113,\n",
              " 'areas': 114,\n",
              " 'trend': 115,\n",
              " 'level3': 116,\n",
              " 'hablar': 117,\n",
              " 'stars': 118,\n",
              " 'xps': 119,\n",
              " 'obile': 120,\n",
              " 'exageradamente': 121,\n",
              " 'dockable': 122,\n",
              " '8700g': 123,\n",
              " 'xb20ex': 124,\n",
              " 'famaliar': 125,\n",
              " 'plannig': 126,\n",
              " 'filmy': 127,\n",
              " 'roofs': 128,\n",
              " 'detract': 129,\n",
              " 'greedy': 130,\n",
              " 'lobster': 131,\n",
              " 'butcher': 132,\n",
              " 'djing': 133,\n",
              " 'shucking': 134,\n",
              " 'porque': 135,\n",
              " '160gb': 136,\n",
              " 'noisesconsback': 137,\n",
              " 'across': 138,\n",
              " 'companyno': 139,\n",
              " 'wouldbuy': 140,\n",
              " 'bassier': 141,\n",
              " 'fj': 142,\n",
              " 'afar': 143,\n",
              " 'illumiated': 144,\n",
              " 'boggling': 145,\n",
              " 'buttongreat': 146,\n",
              " 'accessorie': 147,\n",
              " 'disturbances': 148,\n",
              " 'addicted': 149,\n",
              " 'e72': 150,\n",
              " 'invited': 151,\n",
              " 'rectangular': 152,\n",
              " 'digitals': 153,\n",
              " 'jay': 154,\n",
              " 'through': 155,\n",
              " '250mah': 156,\n",
              " 'wee': 157,\n",
              " 'atras': 158,\n",
              " 'quintessential': 159,\n",
              " 'multicolor': 160,\n",
              " 'tal': 161,\n",
              " 'plasticky': 162,\n",
              " 'usecall': 163,\n",
              " 'reciened': 164,\n",
              " 'slapping': 165,\n",
              " 'companion': 166,\n",
              " 'cip': 167,\n",
              " 'valet': 168,\n",
              " 'althought': 169,\n",
              " 'theblackberry': 170,\n",
              " 'celeste': 171,\n",
              " 'scissors': 172,\n",
              " 'earphonesd': 173,\n",
              " 'itmyself': 174,\n",
              " 'comed': 175,\n",
              " 'apocalypse': 176,\n",
              " 'deapth': 177,\n",
              " 'overwhelm': 178,\n",
              " 'androidforums': 179,\n",
              " 'lookup': 180,\n",
              " 'completing': 181,\n",
              " 'conjunction': 182,\n",
              " 'recalculation': 183,\n",
              " 'distract': 184,\n",
              " '285': 185,\n",
              " 'comprised': 186,\n",
              " 'halpert': 187,\n",
              " 'snatch': 188,\n",
              " 'bush': 189,\n",
              " 'mb525': 190,\n",
              " 'welldespite': 191,\n",
              " 'amazing': 192,\n",
              " 'initiated2': 193,\n",
              " 'anouncements': 194,\n",
              " 'releases': 195,\n",
              " 'guff': 196,\n",
              " 'newbie': 197,\n",
              " 'wrecked': 198,\n",
              " 'adverts': 199,\n",
              " 'features': 200,\n",
              " 'worrying': 201,\n",
              " 'mural': 202,\n",
              " 'carry': 203,\n",
              " 'lapdock': 204,\n",
              " 'magnum': 205,\n",
              " 'concertos': 206,\n",
              " 'listening': 207,\n",
              " 'radios': 208,\n",
              " 'medialink': 209,\n",
              " 'triples': 210,\n",
              " '400v': 211,\n",
              " 'china': 212,\n",
              " 'educational': 213,\n",
              " 'seasy': 214,\n",
              " 'inflexible': 215,\n",
              " 'nova': 216,\n",
              " 'repositionable': 217,\n",
              " 'conveniencia': 218,\n",
              " 'batcopter': 219,\n",
              " 'amaaaazing': 220,\n",
              " 'grippable': 221,\n",
              " 'eased': 222,\n",
              " 'l2b': 223,\n",
              " 'whenmotorola': 224,\n",
              " 'reorganized': 225,\n",
              " 'forehead': 226,\n",
              " 'carbonpak': 227,\n",
              " 'unduly': 228,\n",
              " 'paved': 229,\n",
              " 'cannot': 230,\n",
              " 'emblems': 231,\n",
              " 'choiceother': 232,\n",
              " 'grasping': 233,\n",
              " 'dummy': 234,\n",
              " 'origionaly': 235,\n",
              " 'newsamsung': 236,\n",
              " 'chris': 237,\n",
              " 'start': 238,\n",
              " 'loli': 239,\n",
              " 'atms': 240,\n",
              " 'beastly': 241,\n",
              " 'satisifed': 242,\n",
              " 'unenable': 243,\n",
              " 'does': 244,\n",
              " 'diversification': 245,\n",
              " 'stout': 246,\n",
              " 'cheepest': 247,\n",
              " 'crutchfield': 248,\n",
              " 'fastforward': 249,\n",
              " 'thoughest': 250,\n",
              " 'syllables': 251,\n",
              " 'handing': 252,\n",
              " 'teenaged': 253,\n",
              " 'intellisync': 254,\n",
              " 'gents': 255,\n",
              " 'follicles': 256,\n",
              " 'bury': 257,\n",
              " 'ii': 258,\n",
              " 'deg': 259,\n",
              " 'reassmebled': 260,\n",
              " '10c': 261,\n",
              " 'leopard': 262,\n",
              " '2600mah': 263,\n",
              " 'builky': 264,\n",
              " 'false': 265,\n",
              " 'suitability': 266,\n",
              " 'beyzacases': 267,\n",
              " 'rings': 268,\n",
              " 'river': 269,\n",
              " 'epocrates': 270,\n",
              " 'avarage': 271,\n",
              " 'ngrove': 272,\n",
              " 'scheme': 273,\n",
              " 'wheni': 274,\n",
              " 'imply': 275,\n",
              " 'deffinetly': 276,\n",
              " 'lesson': 277,\n",
              " 'fascination': 278,\n",
              " 'pineer': 279,\n",
              " 'filego': 280,\n",
              " 'cheetah': 281,\n",
              " 'single': 282,\n",
              " 'setfills': 283,\n",
              " 'ext': 284,\n",
              " 'suspicious': 285,\n",
              " 'howevern': 286,\n",
              " 'iqsheild': 287,\n",
              " 'misswith': 288,\n",
              " 'assian': 289,\n",
              " 'telnet': 290,\n",
              " 'nonnononon': 291,\n",
              " 'terrain': 292,\n",
              " 'monyhscto': 293,\n",
              " 'negate': 294,\n",
              " 'birthday': 295,\n",
              " '2ish': 296,\n",
              " 'iphonethe': 297,\n",
              " 'n95s': 298,\n",
              " 'noticing': 299,\n",
              " 'zimbra': 300,\n",
              " '5performance330': 301,\n",
              " 'brainbusting': 302,\n",
              " 'frequencied': 303,\n",
              " 'minimise': 304,\n",
              " 'thecorrect': 305,\n",
              " 'woudl': 306,\n",
              " 'battle': 307,\n",
              " '6v': 308,\n",
              " 'both': 309,\n",
              " 'arggg': 310,\n",
              " 'thatthe': 311,\n",
              " 'stating': 312,\n",
              " 'guys': 313,\n",
              " 'insideout': 314,\n",
              " 'treatments': 315,\n",
              " 'advertisedit': 316,\n",
              " 'pentium': 317,\n",
              " 'modes': 318,\n",
              " 'concierge': 319,\n",
              " 'predictable': 320,\n",
              " 'dislodge': 321,\n",
              " 'tryna': 322,\n",
              " 'spg': 323,\n",
              " '1150mah': 324,\n",
              " 'comfortablecons': 325,\n",
              " 'supprt': 326,\n",
              " 'chichi': 327,\n",
              " 'life360': 328,\n",
              " 'unread': 329,\n",
              " 'matched': 330,\n",
              " 'abundance': 331,\n",
              " 'windsurfing': 332,\n",
              " 'maxing': 333,\n",
              " 'verisons': 334,\n",
              " 'backpack': 335,\n",
              " 'devolved': 336,\n",
              " 'basic': 337,\n",
              " 'inconvenients': 338,\n",
              " 'geddamuri': 339,\n",
              " 'tremeendous': 340,\n",
              " 'batterythe': 341,\n",
              " '108': 342,\n",
              " 'feb': 343,\n",
              " 'pk': 344,\n",
              " 'motivate': 345,\n",
              " 'possessions': 346,\n",
              " 'transiting': 347,\n",
              " 'pendulous': 348,\n",
              " 'flee': 349,\n",
              " 'meh': 350,\n",
              " 'streching': 351,\n",
              " 'bluettoth': 352,\n",
              " 'comingup': 353,\n",
              " 'beyoind': 354,\n",
              " 'by': 355,\n",
              " 'camewith': 356,\n",
              " 'linear': 357,\n",
              " 'shifted': 358,\n",
              " '8700c2': 359,\n",
              " 'traditional': 360,\n",
              " 'reviews': 361,\n",
              " 'sterdy': 362,\n",
              " 'pb': 363,\n",
              " 'lanyard': 364,\n",
              " 'advice': 365,\n",
              " 'intermec': 366,\n",
              " 'saitechi': 367,\n",
              " 'brilliance': 368,\n",
              " 'slack': 369,\n",
              " 'q9m': 370,\n",
              " 'rein': 371,\n",
              " 'deposit': 372,\n",
              " '2690': 373,\n",
              " 'they': 374,\n",
              " 'slidepresenter': 375,\n",
              " '40cm': 376,\n",
              " 'experiment': 377,\n",
              " 'knuckle': 378,\n",
              " 'onesfrom': 379,\n",
              " 'preforms': 380,\n",
              " 'urls': 381,\n",
              " 'para': 382,\n",
              " '62': 383,\n",
              " 'clanging': 384,\n",
              " 'flicks': 385,\n",
              " 'usageedit': 386,\n",
              " 'shirt': 387,\n",
              " 'cpus': 388,\n",
              " 'weight': 389,\n",
              " 'sleve': 390,\n",
              " 'lifter': 391,\n",
              " 'costanza': 392,\n",
              " 'irvine': 393,\n",
              " 'vents': 394,\n",
              " 'taks': 395,\n",
              " 'diddnt': 396,\n",
              " 'underlying': 397,\n",
              " '150mb': 398,\n",
              " 'wont': 399,\n",
              " 'q10': 400,\n",
              " 'pam': 401,\n",
              " 'optimal': 402,\n",
              " 'diving': 403,\n",
              " 'oils': 404,\n",
              " 'originated': 405,\n",
              " 'elevation': 406,\n",
              " 'iphonesync': 407,\n",
              " 't9': 408,\n",
              " 'msn': 409,\n",
              " 'unwillingly': 410,\n",
              " 'v3e': 411,\n",
              " 'squeaking': 412,\n",
              " 'bluetoooth': 413,\n",
              " 'docomfort': 414,\n",
              " 'turned': 415,\n",
              " 'community': 416,\n",
              " 'recommendt': 417,\n",
              " 'capitalize': 418,\n",
              " 'buysamsung': 419,\n",
              " 'coupe': 420,\n",
              " 'evolutions': 421,\n",
              " 'braces': 422,\n",
              " 'beat': 423,\n",
              " 'particulars': 424,\n",
              " 'hx1': 425,\n",
              " 'antics': 426,\n",
              " 'pencilthe': 427,\n",
              " 'sk': 428,\n",
              " '00am': 429,\n",
              " 'transport': 430,\n",
              " 'adhering': 431,\n",
              " 'psone': 432,\n",
              " 'priorities': 433,\n",
              " 'inputing': 434,\n",
              " 'surely': 435,\n",
              " 'virtues': 436,\n",
              " 'gusts': 437,\n",
              " 'extactly': 438,\n",
              " 'money': 439,\n",
              " 'karen': 440,\n",
              " '8hrs': 441,\n",
              " 'smoothy': 442,\n",
              " 'eight': 443,\n",
              " 'outsmoking': 444,\n",
              " 'thingee': 445,\n",
              " 'alternator': 446,\n",
              " 'coring': 447,\n",
              " 'speakerthat': 448,\n",
              " 'leaping': 449,\n",
              " 'buzzes': 450,\n",
              " '1420mah': 451,\n",
              " 'outnumber': 452,\n",
              " '4x4': 453,\n",
              " 'describing': 454,\n",
              " 'ssssssssssssssssssss': 455,\n",
              " 'facilmente': 456,\n",
              " 'visibledoes': 457,\n",
              " 'song': 458,\n",
              " 'vibrations': 459,\n",
              " 'flappiness': 460,\n",
              " 'i9020t': 461,\n",
              " 'africa': 462,\n",
              " 'boss': 463,\n",
              " 'thhis': 464,\n",
              " 'b0002gubis': 465,\n",
              " 'fetching': 466,\n",
              " 'motnhs': 467,\n",
              " 'nonslip': 468,\n",
              " 'dollarsgiving': 469,\n",
              " 'purch': 470,\n",
              " '2009': 471,\n",
              " 'boasting': 472,\n",
              " 'collarbones': 473,\n",
              " 'cell': 474,\n",
              " '90': 475,\n",
              " 'lates': 476,\n",
              " 'cred': 477,\n",
              " 'nexux': 478,\n",
              " 'leave': 479,\n",
              " 'fujifilm': 480,\n",
              " 'boot': 481,\n",
              " 'origin': 482,\n",
              " 'townhome': 483,\n",
              " 'ahaha': 484,\n",
              " 'bt530': 485,\n",
              " 'stupidly': 486,\n",
              " 'inefficient': 487,\n",
              " 'penalties': 488,\n",
              " 'suberb': 489,\n",
              " '11gsound': 490,\n",
              " 'clipping': 491,\n",
              " 'genericos': 492,\n",
              " 'dvb': 493,\n",
              " 'circular': 494,\n",
              " 'cramming': 495,\n",
              " 'tunerthis': 496,\n",
              " 'machinery': 497,\n",
              " 'handsomely': 498,\n",
              " 'flimsyness': 499,\n",
              " 'nonfunctional': 500,\n",
              " 'february': 501,\n",
              " 'iphone5s': 502,\n",
              " 'outdone': 503,\n",
              " 'rightaway': 504,\n",
              " 'deice': 505,\n",
              " 'kit': 506,\n",
              " 'restricts': 507,\n",
              " 'elementary': 508,\n",
              " 'bunny': 509,\n",
              " 'titles': 510,\n",
              " 'fizzle': 511,\n",
              " 'loaner': 512,\n",
              " 'mesh': 513,\n",
              " '1hr': 514,\n",
              " 'crosswise': 515,\n",
              " 'replys': 516,\n",
              " 'restoredthey': 517,\n",
              " 'cruz': 518,\n",
              " 'lucid': 519,\n",
              " 'wellcon': 520,\n",
              " 'tc': 521,\n",
              " 'abriendo': 522,\n",
              " 'worthy': 523,\n",
              " 'bz60': 524,\n",
              " 'required': 525,\n",
              " '96': 526,\n",
              " 'conclusioni': 527,\n",
              " 'palma': 528,\n",
              " 'puttering': 529,\n",
              " 's5660': 530,\n",
              " 'integrator': 531,\n",
              " 'leisurely': 532,\n",
              " 'tingly': 533,\n",
              " 'emphatic': 534,\n",
              " 'subscribed': 535,\n",
              " 'strangest': 536,\n",
              " 'accessorize': 537,\n",
              " 'mandarin': 538,\n",
              " 's308': 539,\n",
              " 'enslaved': 540,\n",
              " 'discerning': 541,\n",
              " 'dailycellular': 542,\n",
              " 'propduct': 543,\n",
              " 'reciting': 544,\n",
              " 'headsetusb': 545,\n",
              " 'writing': 546,\n",
              " 'scredrivers': 547,\n",
              " 'awfull': 548,\n",
              " 'priduct': 549,\n",
              " 'monotony': 550,\n",
              " 'tantamount': 551,\n",
              " 'considerable': 552,\n",
              " 'improvments': 553,\n",
              " 'suspected': 554,\n",
              " 'kolay': 555,\n",
              " 'o03': 556,\n",
              " 'funcional': 557,\n",
              " 'pixelate': 558,\n",
              " 'jeri': 559,\n",
              " 'dinc2htc': 560,\n",
              " 'unridiculous': 561,\n",
              " 'wake': 562,\n",
              " 'submenus': 563,\n",
              " 'feelign': 564,\n",
              " '3gp': 565,\n",
              " 'withram': 566,\n",
              " 'jostling': 567,\n",
              " 'jewel': 568,\n",
              " 'noname': 569,\n",
              " 'smartphonesfor': 570,\n",
              " 'fam': 571,\n",
              " 'invisible': 572,\n",
              " 'saty': 573,\n",
              " 'chicken': 574,\n",
              " 'minimized': 575,\n",
              " 'aduro': 576,\n",
              " 'walkers': 577,\n",
              " '1of': 578,\n",
              " 'jazzier': 579,\n",
              " 'blitz': 580,\n",
              " 'zboost': 581,\n",
              " 'curveandnokia': 582,\n",
              " 'gui': 583,\n",
              " 'thankful': 584,\n",
              " 'wav': 585,\n",
              " 'ahhhhhhrrrr': 586,\n",
              " '15apr12': 587,\n",
              " 'ouchy': 588,\n",
              " 'wanting': 589,\n",
              " 'smoking': 590,\n",
              " 'turnaround': 591,\n",
              " 'unding': 592,\n",
              " 'authentication': 593,\n",
              " 'polarization': 594,\n",
              " 'myamazonbasics': 595,\n",
              " 'meagadeal': 596,\n",
              " 'carpeted': 597,\n",
              " 'travelinghome': 598,\n",
              " 'iterate': 599,\n",
              " 'as20j': 600,\n",
              " 'alays': 601,\n",
              " 'imposable': 602,\n",
              " '101': 603,\n",
              " 'meshes': 604,\n",
              " 'related': 605,\n",
              " 'disorient': 606,\n",
              " 'johnny': 607,\n",
              " 'crystalline': 608,\n",
              " 'allcheapeasy': 609,\n",
              " 'imaxpower': 610,\n",
              " 'copycat': 611,\n",
              " 'logn': 612,\n",
              " 'polite': 613,\n",
              " 'boought': 614,\n",
              " 'optic': 615,\n",
              " 'protecor': 616,\n",
              " 'arm': 617,\n",
              " 'moshu': 618,\n",
              " 'overhanging': 619,\n",
              " 'disturbance': 620,\n",
              " 'gravel': 621,\n",
              " 'fallsset': 622,\n",
              " 'sp109': 623,\n",
              " '6am': 624,\n",
              " 'lostinternet': 625,\n",
              " 'otherthings': 626,\n",
              " 'irresponsive': 627,\n",
              " 'venice': 628,\n",
              " '3months': 629,\n",
              " 'santa': 630,\n",
              " 'townhouse': 631,\n",
              " 'shove': 632,\n",
              " '801242': 633,\n",
              " 'chapped': 634,\n",
              " 'ejector': 635,\n",
              " 'differ': 636,\n",
              " 'brightest': 637,\n",
              " 'lofty': 638,\n",
              " '98686h': 639,\n",
              " 'pocketknife': 640,\n",
              " 'lmr': 641,\n",
              " 'coming': 642,\n",
              " 'bodys': 643,\n",
              " 'fit4': 644,\n",
              " 'rag': 645,\n",
              " 'whencarrying': 646,\n",
              " 'arte': 647,\n",
              " 'stunner': 648,\n",
              " 'pressure': 649,\n",
              " 'strayed': 650,\n",
              " 'merger': 651,\n",
              " 'uma': 652,\n",
              " '2mpbs': 653,\n",
              " 'sandal': 654,\n",
              " 'electronicos': 655,\n",
              " 'fingerprint': 656,\n",
              " 'timesno': 657,\n",
              " 'erasing': 658,\n",
              " 'envelope': 659,\n",
              " 'science': 660,\n",
              " 'statuscons': 661,\n",
              " 'partitions': 662,\n",
              " 'cherrywood': 663,\n",
              " 'oem': 664,\n",
              " 'watchdog': 665,\n",
              " 'bluster': 666,\n",
              " 'pitch': 667,\n",
              " 'sesitivety': 668,\n",
              " 'i3': 669,\n",
              " 'l216': 670,\n",
              " 'umungst': 671,\n",
              " 'timex': 672,\n",
              " 'sizespeakers': 673,\n",
              " 'nosleep': 674,\n",
              " 'earhooks': 675,\n",
              " 'smothly': 676,\n",
              " 'mycast': 677,\n",
              " 'simplified': 678,\n",
              " 'themquality': 679,\n",
              " 'flyweight': 680,\n",
              " 'rib': 681,\n",
              " 'reinforce': 682,\n",
              " 'codependent': 683,\n",
              " 'judged': 684,\n",
              " 'dragged': 685,\n",
              " 'qyuality': 686,\n",
              " 'worries': 687,\n",
              " 'hi': 688,\n",
              " 'extraordinarily': 689,\n",
              " 'gribby': 690,\n",
              " 'hagas': 691,\n",
              " 'bupkis': 692,\n",
              " 'drawing': 693,\n",
              " 'greenshields': 694,\n",
              " 'comfortable2': 695,\n",
              " 'lying': 696,\n",
              " 'headers': 697,\n",
              " 'unclipped': 698,\n",
              " 'asphalt3d': 699,\n",
              " 'macbook': 700,\n",
              " 'speakerphonevia': 701,\n",
              " 'htcevos': 702,\n",
              " 'marque': 703,\n",
              " 'tx500': 704,\n",
              " 'svcs': 705,\n",
              " 'arthritis': 706,\n",
              " 'sentitivity': 707,\n",
              " 't5': 708,\n",
              " 'principally': 709,\n",
              " 'previews': 710,\n",
              " 'inboxes': 711,\n",
              " 'mlia': 712,\n",
              " 'surprsied': 713,\n",
              " 'excess': 714,\n",
              " 'keyboardtriple': 715,\n",
              " '16gbnikon': 716,\n",
              " 'thecommuter': 717,\n",
              " 'control': 718,\n",
              " '3500mahbattery': 719,\n",
              " 'setuporiginally': 720,\n",
              " 'nonremoveable': 721,\n",
              " 'cluttered': 722,\n",
              " 'fix': 723,\n",
              " 'earphonesand': 724,\n",
              " 'hott': 725,\n",
              " 'tech': 726,\n",
              " '1981': 727,\n",
              " 'fro': 728,\n",
              " 'nmo': 729,\n",
              " 'plunked': 730,\n",
              " 'dumbo': 731,\n",
              " 'canal': 732,\n",
              " 'wither': 733,\n",
              " 'relooking': 734,\n",
              " 'productfor': 735,\n",
              " 'arenas': 736,\n",
              " 'laptop': 737,\n",
              " 'timebefore': 738,\n",
              " 'pleastantly': 739,\n",
              " 'onther': 740,\n",
              " 'evolution': 741,\n",
              " 'eliminating': 742,\n",
              " 'basses': 743,\n",
              " 'smacking': 744,\n",
              " 'warrantywhich': 745,\n",
              " 'designi': 746,\n",
              " 'webform': 747,\n",
              " '13i': 748,\n",
              " 'comeout': 749,\n",
              " 'r1200gs': 750,\n",
              " 'pops': 751,\n",
              " 'maxpedition': 752,\n",
              " 'hurricanes': 753,\n",
              " 'clip': 754,\n",
              " 'it2': 755,\n",
              " 'bt500': 756,\n",
              " 'reluctant': 757,\n",
              " 'ringtone': 758,\n",
              " 'subtracted': 759,\n",
              " 'expelkin': 760,\n",
              " 'designated': 761,\n",
              " 'blackeberry': 762,\n",
              " 'hol': 763,\n",
              " 'crush': 764,\n",
              " '453g': 765,\n",
              " 'etc': 766,\n",
              " 'lunches': 767,\n",
              " 'hahahahahah': 768,\n",
              " 'immediately': 769,\n",
              " 'overextended': 770,\n",
              " 'dignified': 771,\n",
              " 'amplifiers': 772,\n",
              " '49asu': 773,\n",
              " 'stops': 774,\n",
              " 'sph': 775,\n",
              " 'screen7': 776,\n",
              " 'b003tj3oy8': 777,\n",
              " 'submission': 778,\n",
              " '2005if': 779,\n",
              " 'thursday': 780,\n",
              " 'exceeds': 781,\n",
              " 'basebonus': 782,\n",
              " 'vibrantness': 783,\n",
              " 'catastrophic': 784,\n",
              " 'ipurchase': 785,\n",
              " 'aldo': 786,\n",
              " 'loud6': 787,\n",
              " 'spetrum': 788,\n",
              " 'otras': 789,\n",
              " 'vulnerable': 790,\n",
              " 'dodgier': 791,\n",
              " 'dealies': 792,\n",
              " 'entails': 793,\n",
              " 's2but': 794,\n",
              " 'whooping': 795,\n",
              " '49': 796,\n",
              " 'chargeris': 797,\n",
              " 'chatight': 798,\n",
              " 'george': 799,\n",
              " 'cronovich': 800,\n",
              " 'dtopped': 801,\n",
              " 'stubble': 802,\n",
              " 'lilac': 803,\n",
              " 'brandfor': 804,\n",
              " 'exolife': 805,\n",
              " 'startechnollusion': 806,\n",
              " 'husband': 807,\n",
              " 'drivingiphone': 808,\n",
              " 'checkers': 809,\n",
              " 'mantengo': 810,\n",
              " 'influenced': 811,\n",
              " 'children': 812,\n",
              " 'frontier': 813,\n",
              " 'delightfull': 814,\n",
              " 'mmsserver': 815,\n",
              " 'degees': 816,\n",
              " 'scenery': 817,\n",
              " '4runner': 818,\n",
              " 'taht': 819,\n",
              " 'mission': 820,\n",
              " '400': 821,\n",
              " 'hopelessly': 822,\n",
              " 'governs': 823,\n",
              " 'fattens': 824,\n",
              " 'macbooks': 825,\n",
              " 'northeast': 826,\n",
              " 'ais': 827,\n",
              " 'vanities': 828,\n",
              " 'battalion': 829,\n",
              " 'rundown': 830,\n",
              " 'dads': 831,\n",
              " 'pandigital': 832,\n",
              " 'upstairs': 833,\n",
              " 'really': 834,\n",
              " 'kdc': 835,\n",
              " 'dearest': 836,\n",
              " 'glaringfault': 837,\n",
              " 'timew': 838,\n",
              " '1010wins': 839,\n",
              " 'h820': 840,\n",
              " 'infringement': 841,\n",
              " 'proportion': 842,\n",
              " 'supra': 843,\n",
              " 'whaaa': 844,\n",
              " 'fussjust': 845,\n",
              " 'walkmans': 846,\n",
              " 'inca': 847,\n",
              " 'mods': 848,\n",
              " 'geous': 849,\n",
              " 'noticable': 850,\n",
              " 'obstructing': 851,\n",
              " 'rock': 852,\n",
              " 'tweet': 853,\n",
              " 'statistics': 854,\n",
              " 'comoda': 855,\n",
              " 'italy': 856,\n",
              " 'cheated': 857,\n",
              " 'elastomer': 858,\n",
              " 'ordred': 859,\n",
              " 'nettles': 860,\n",
              " 'grammatical': 861,\n",
              " 'calibration': 862,\n",
              " 'docx': 863,\n",
              " 'memorize': 864,\n",
              " 'arse': 865,\n",
              " 'cuttes': 866,\n",
              " 'riddance': 867,\n",
              " 'piled': 868,\n",
              " 'uninitiated': 869,\n",
              " 'wirelesswater': 870,\n",
              " 'narrativei': 871,\n",
              " '1980s': 872,\n",
              " 'remembering': 873,\n",
              " 'plactis': 874,\n",
              " 'annoys': 875,\n",
              " 'iphone3': 876,\n",
              " 'irresponsible': 877,\n",
              " 'devastated': 878,\n",
              " 'whitish': 879,\n",
              " 'winning': 880,\n",
              " 'iphoneincludes': 881,\n",
              " 'zeiss': 882,\n",
              " 'rigger': 883,\n",
              " 'noch': 884,\n",
              " 'measure': 885,\n",
              " 'jeeps': 886,\n",
              " 'painstakingly': 887,\n",
              " 'math': 888,\n",
              " 'lfe': 889,\n",
              " 'trabi': 890,\n",
              " 'lil': 891,\n",
              " 'andboxwave': 892,\n",
              " 'signifantly': 893,\n",
              " 'specialize': 894,\n",
              " 'triangles': 895,\n",
              " 'freebsd': 896,\n",
              " 'brownsing': 897,\n",
              " 'covercons': 898,\n",
              " 'zombie': 899,\n",
              " 'atachments': 900,\n",
              " 'tele': 901,\n",
              " 'sleepers': 902,\n",
              " 'constantally': 903,\n",
              " 'jumbling': 904,\n",
              " 'necklaces': 905,\n",
              " 'howeverrrrrrr': 906,\n",
              " 'gen': 907,\n",
              " 'hyper': 908,\n",
              " 'sufficient': 909,\n",
              " 'fairing': 910,\n",
              " 'phenomenon': 911,\n",
              " 'toch': 912,\n",
              " 'cablessitting': 913,\n",
              " 'unrestricted': 914,\n",
              " 'blob': 915,\n",
              " 'visa': 916,\n",
              " 'infamous': 917,\n",
              " 'sideoverall': 918,\n",
              " 'piece': 919,\n",
              " 'importunities': 920,\n",
              " 'dropage': 921,\n",
              " 'justified': 922,\n",
              " 'c240': 923,\n",
              " 'uo': 924,\n",
              " 'clasped': 925,\n",
              " 'thinkpad': 926,\n",
              " 'proably': 927,\n",
              " '2ft': 928,\n",
              " 'communincate': 929,\n",
              " 'odin': 930,\n",
              " 'favorite': 931,\n",
              " 'dear': 932,\n",
              " 'otterboxes': 933,\n",
              " 'heaving': 934,\n",
              " 'proyected': 935,\n",
              " 'althoi': 936,\n",
              " 'looker': 937,\n",
              " 'sennheiser': 938,\n",
              " 'behaves': 939,\n",
              " 'frosting': 940,\n",
              " 'batteryi': 941,\n",
              " 'dayfor': 942,\n",
              " 'whatsapp': 943,\n",
              " 'conferencing': 944,\n",
              " 'sped': 945,\n",
              " 'razer': 946,\n",
              " 'chargerand': 947,\n",
              " 'compress': 948,\n",
              " 'uploading': 949,\n",
              " 'lether': 950,\n",
              " 'roataing': 951,\n",
              " 'bmi': 952,\n",
              " 'pointless': 953,\n",
              " 'costly': 954,\n",
              " 'burger': 955,\n",
              " 'faraday': 956,\n",
              " 'poorer': 957,\n",
              " 'expending': 958,\n",
              " 'isp': 959,\n",
              " 'earcable': 960,\n",
              " 'reallyan': 961,\n",
              " 'aesthetic': 962,\n",
              " 'hasalso': 963,\n",
              " 'copying': 964,\n",
              " 'approximate': 965,\n",
              " '18hours': 966,\n",
              " 'badthis': 967,\n",
              " 'gts': 968,\n",
              " 'stalk': 969,\n",
              " 'roaster': 970,\n",
              " 'lowrance': 971,\n",
              " 'ipohne': 972,\n",
              " 'largecapacity': 973,\n",
              " 'filename': 974,\n",
              " 'evenuse': 975,\n",
              " 'sharply': 976,\n",
              " 'redeem': 977,\n",
              " '4v': 978,\n",
              " 'sus': 979,\n",
              " 'junkpiece': 980,\n",
              " 'grr': 981,\n",
              " 'scientist': 982,\n",
              " 'di': 983,\n",
              " 'itemsmall': 984,\n",
              " 'departure': 985,\n",
              " 'hangouts': 986,\n",
              " 'p1000': 987,\n",
              " 'timeand': 988,\n",
              " 'm100': 989,\n",
              " 'allupens': 990,\n",
              " 'punches': 991,\n",
              " 'redise': 992,\n",
              " 'biomic': 993,\n",
              " 'yearsunfortunately': 994,\n",
              " 'attractive': 995,\n",
              " 'wonderful': 996,\n",
              " 'variability': 997,\n",
              " 'waken': 998,\n",
              " 'tohave': 999,\n",
              " ...}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating One-Hot Encoding"
      ],
      "metadata": {
        "id": "Qc4E7MGVwnVA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def one_hot_encoding(vocab:list, word: str) -> torch.Tensor:\n",
        "    important_index = vocab.index(word)\n",
        "\n",
        "    return torch.tensor([1 if i == important_index else 0 for i in range(len(vocab))])"
      ],
      "metadata": {
        "id": "3oiheWt8wmbA"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CBOW Model"
      ],
      "metadata": {
        "id": "1n72VzTCUe6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "WINDOW_SIZE = 10\n",
        "EMB_SIZE = 30"
      ],
      "metadata": {
        "id": "JDAIGb6XlMs6"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting a tokenize sentence in training samples\n",
        "def generate_samples(tokenized_sentence: list, window_size: int) -> list:\n",
        "    samples = []\n",
        "\n",
        "    for i in range(len(tokenized_sentence) - window_size):\n",
        "        if len(tokenized_sentence[i+1: i+1+window_size]) == window_size:\n",
        "            samples.append((\" \".join(tokenized_sentence[i+1: i+1+window_size]), tokenized_sentence[i]))\n",
        "\n",
        "    return samples\n",
        "\n",
        "\n",
        "# Converting the entire reviews dataset into training samples\n",
        "def generate_training_data(tokenized_ps: pd.core.series.Series, window_size: int) -> list:\n",
        "    training_samples = []\n",
        "\n",
        "    for tokenized_sentence in tokenized_ps:\n",
        "        training_samples += generate_samples(tokenized_sentence, window_size)\n",
        "\n",
        "    return training_samples"
      ],
      "metadata": {
        "id": "7muL80rMXqQ4"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_samples = generate_training_data(tokenized_ps, WINDOW_SIZE)\n",
        "\n",
        "training_samples[90:99]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "si9Gta7wklgW",
        "outputId": "1a65b044-ce77-4ab8-baf5-6d7218e1e7d7"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('included free screen protector i never received one though its', 'and'),\n",
              " ('free screen protector i never received one though its not', 'included'),\n",
              " ('screen protector i never received one though its not big', 'free'),\n",
              " ('protector i never received one though its not big deal', 'screen'),\n",
              " ('i never received one though its not big deal it', 'protector'),\n",
              " ('never received one though its not big deal it would', 'i'),\n",
              " ('received one though its not big deal it would ve', 'never'),\n",
              " ('one though its not big deal it would ve been', 'received'),\n",
              " ('though its not big deal it would ve been nice', 'one')]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the Model"
      ],
      "metadata": {
        "id": "nVYcsS1bx7oN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CBOW(nn.Module):\n",
        "    def __init__(self, window_size: int, vocab: str, hidden_units: int) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "        self.vocab = vocab\n",
        "\n",
        "        self.projection_layer = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=window_size*len(vocab), out_features=hidden_units)\n",
        "        )\n",
        "\n",
        "        self.embedding_layer = nn.Linear(in_features=hidden_units, out_features=hidden_units)\n",
        "\n",
        "\n",
        "    def forward(self, contex_sentence: str): # x: shape=(1, window_size, vocab_size)\n",
        "        print()\n",
        "        print(torch.tensor([torch.LongTensor(one_hot_encoding(self.vocab, word)).to(device) for word in contex_sentence.split()]))\n",
        "        x = torch.tensor([torch.LongTensor(one_hot_encoding(self.vocab, word)).to(device) for word in contex_sentence.split()]).unsqueeze(dim=0).to(device)\n",
        "\n",
        "        return self.embedding_layer(self.projection_layer(x))"
      ],
      "metadata": {
        "id": "WpdizXYXsyqZ"
      },
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Initializing the Model"
      ],
      "metadata": {
        "id": "1hFdTDJQx8-0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cbow_model = CBOW(WINDOW_SIZE, vocab, EMB_SIZE).to(device)\n",
        "\n",
        "cbow_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dE2wVk-zxpE5",
        "outputId": "2fefca8f-dee7-42cc-f592-dd8be88e3341"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CBOW(\n",
              "  (projection_layer): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=420380, out_features=30, bias=True)\n",
              "  )\n",
              "  (embedding_layer): Linear(in_features=30, out_features=30, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Loss Function and Optimizer"
      ],
      "metadata": {
        "id": "fxgJ5BQvyQr2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = optim.Adam(params=cbow_model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "K70U_VNAyNfk"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting Accuracy Metric"
      ],
      "metadata": {
        "id": "HvWc5kKOyjSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_fn(logit: torch.Tensor, labels: torch.Tensor) -> float:\n",
        "    pred_label_index = torch.softmax(logit, dim=1).argmax(dim=1).item()\n",
        "\n",
        "    return (labels[0][pred_label_index].item() == 1) * 100"
      ],
      "metadata": {
        "id": "1n5tLuZsyiow"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the Training Loop"
      ],
      "metadata": {
        "id": "5HMAz0e_1iTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(model, epochs, training_samples, loss_fn, accuracy_fn, opt):\n",
        "    history = []\n",
        "\n",
        "    print(\"Starting Process...\")\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        epoch_loss, epoch_acc = 0, 0\n",
        "\n",
        "        model.train()\n",
        "        for sample in tqdm(training_samples):\n",
        "            y_label = torch.LongTensor(one_hot_encoding(model.vocab, sample[1])).unsqueeze(dim=0)\n",
        "            logit = model(sample[0])\n",
        "            # loss = loss_fn(logit, y_label)\n",
        "\n",
        "            # epoch_loss += loss.item()\n",
        "            # epoch_acc += accuracy_fn(logit, y_label)\n",
        "\n",
        "            # opt.zero_grad()\n",
        "            # loss.backward()\n",
        "            # opt.step()\n",
        "\n",
        "        epoch_loss /= len(training_samples)\n",
        "        epoch_acc /= len(training_samples)\n",
        "\n",
        "        print({\"epoch\": epoch, \"loss\": epoch_loss, \"acc(%)\": epoch_acc})\n",
        "        history.append({\"epoch\": epoch, \"loss\": epoch_loss, \"acc(%)\": epoch_acc})\n",
        "\n",
        "    print(\"Process Successfully Completed...\")\n",
        "\n",
        "    return history"
      ],
      "metadata": {
        "id": "dAUlgqQw1h1h"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model"
      ],
      "metadata": {
        "id": "3QJk26HE3mRn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = fit(cbow_model, 5, training_samples, loss_fn, accuracy_fn, opt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "W-ETikIa3lkd",
        "outputId": "d4a4290d-9938-43c8-da1d-8c1c63008e76"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Process...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/3975842 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-112-2b9a58ee071f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcbow_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-111-3d3dd2deec7d>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, epochs, training_samples, loss_fn, accuracy_fn, opt)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_samples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0my_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m             \u001b[0mlogit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m             \u001b[0;31m# loss = loss_fn(logit, y_label)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-107-0f89dd5ec337>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, contex_sentence)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontex_sentence\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# x: shape=(1, window_size, vocab_size)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontex_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_hot_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontex_sentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: only integer tensors of a single element can be converted to an index"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-5FtWThr3vTN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}