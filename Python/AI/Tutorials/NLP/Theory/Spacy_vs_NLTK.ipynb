{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Python Libraries for NLP\n",
        "\n",
        "There are a lot of libraries that provide NLP with the most popular being:\n",
        "1. Pytorch\n",
        "2. Tensorflow\n",
        "3. Gensim\n",
        "4. Spacy\n",
        "5. NLTK\n",
        "\n",
        "We will examine the last two, `Space` and `NLTK`"
      ],
      "metadata": {
        "id": "TONfJS8xgRYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the core package for english that spacy requires\n",
        "!python -m spacy download en_core_web_sm -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYua7H30g5UH",
        "outputId": "4df83018-714f-4ad1-eae5-cbf83b5dc883"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/cuda/__init__.py:546: UserWarning: Can't initialize NVML\n",
            "  warnings.warn(\"Can't initialize NVML\")\n",
            "2023-04-05 08:23:42.137544: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "2023-04-05 08:23:44.794234: E tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:266] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m75.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import nltk"
      ],
      "metadata": {
        "id": "vYbwFw4bg6L0"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We need to download the main package for also NLTK\n",
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2aYOFOSkVwS",
        "outputId": "d88af125-49c9-429f-9c06-27fce487d674"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Differences Between Space and NLTK\n",
        "\n",
        "The main difference between Space and NLTK is that Space is `object-oriented` and NLTK is mainly a `string processing` library.\n",
        "\n",
        "Another difference is that Spacy provides most efficient NLP algorithm for a given task, and NLTK provides access to many algorithms, giving us more customization options.\n",
        "\n",
        "NLTK is a powerfull library, but in order to unveil its powers we need to process it and tweak it to our needs."
      ],
      "metadata": {
        "id": "E2Xdj2WieRE_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performing Tokenization using Spacy"
      ],
      "metadata": {
        "id": "mYT2O0NShtp2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the nlp object\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Loading the document\n",
        "doc = nlp(\"Dr. Strange loves pav bhaji of mubai. Hulk loves chaat of delhi\")\n",
        "\n",
        "# Printing the sentecne of the document\n",
        "for sentence in doc.sents:\n",
        "    print(sentence)\n",
        "\n",
        "# Pefroming word tokenization\n",
        "for senetence in doc.sents:\n",
        "    print()\n",
        "    for word in senetence:\n",
        "        print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ExISyLZOg9E4",
        "outputId": "863b736b-e6f2-4e05-8aaf-a0b5f6906bd1"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dr. Strange loves pav bhaji of mubai.\n",
            "Hulk loves chaat of delhi\n",
            "\n",
            "Dr.\n",
            "Strange\n",
            "loves\n",
            "pav\n",
            "bhaji\n",
            "of\n",
            "mubai\n",
            ".\n",
            "\n",
            "Hulk\n",
            "loves\n",
            "chaat\n",
            "of\n",
            "delhi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performing Tokenization using NLTK"
      ],
      "metadata": {
        "id": "p5T5g_uwibCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK provides a lot of tokeniztion method\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "B5QZLvj4ieYh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_tokenize(\"Dr. Strange loves pav bhaji of mubai. Hulk loves chaat of delhi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xj2CDHiVkJso",
        "outputId": "160a5a8f-f935-42e2-96a9-dc3ea2b1aa2a"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Dr.', 'Strange loves pav bhaji of mubai.', 'Hulk loves chaat of delhi']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word_tokenize(\"Dr. Strange loves pav bhaji of mubai. Hulk loves chaat of delhi\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3GeE1AgDlKLf",
        "outputId": "01608549-42da-4129-9685-242c12391b83"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Dr',\n",
              " '.',\n",
              " 'Strange',\n",
              " 'loves',\n",
              " 'pav',\n",
              " 'bhaji',\n",
              " 'of',\n",
              " 'mubai',\n",
              " '.',\n",
              " 'Hulk',\n",
              " 'loves',\n",
              " 'chaat',\n",
              " 'of',\n",
              " 'delhi']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    }
  ]
}