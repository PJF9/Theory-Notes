{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "q9IKQnGdUAGw",
        "T-5EWyfVegrf",
        "Z9iWdTPdUSzd",
        "NznbJyS9beMd",
        "KtX3QJ88o6xY",
        "m_IUNee6aFYA",
        "VnOx2vH0c759",
        "LZ1Cp916dp-q",
        "0w9LDFotnV3r",
        "nhf1Y7TjqKEL",
        "2CBrBcP-rE_a",
        "N8RPsWlekrBr"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## What this File Contains?\n",
        "\n",
        "This file contains all the core and helpfull function for supervised learning and Generative Adversarial Netwrorks. With more details it contains:\n",
        "* Data Preparation:\n",
        "    1. `download_dataset_zip(source, destination, if_exists_stop, delete_zip)`\n",
        "    2. `download_image(source, destination, if_exists_stop)`\n",
        "    2. `plot_images_before_and_after(images_path_list, transforms)`\n",
        "    3. `split_dataset(dataset, split_prop, seed)`\n",
        "    4. `show_image_grid(images, denorm_fn, n_rows, fig_size)`\n",
        "\n",
        "* Evaluating:\n",
        "    1. `plot_loss_curve(results, fig_size, font_size)`\n",
        "    2. `plot_acc_curve(results, fig_size, font_size)`\n",
        "    3. `plot_image_predictions(model, class_names, image_path, transforms)`\n",
        "    4. `create_writer(experiment_name, model_name, extras)`\n",
        "    5. `accuracy_fn(model_logits, labels)`\n",
        "\n",
        "* Training:\n",
        "    * a) Supervised Learning:\n",
        "        1. `training_step(model, train_dl, loss_fn, eval_fn, opt)`\n",
        "        2. `validation_step(model, valid_dl, loss_fn, eval_fn)`\n",
        "        3. `fit(model, epochs, train_dl, valid_dl, loss_fn, eval_fn, opt, writer)`\n",
        "\n",
        "    * b) GAN:\n",
        "        1. `train_discriminator(discriminator, generator, real_image_batch, loss_fn, opt_dis, opt_gen, latent_size`\n",
        "        2. `train_generator(discriminator, generator, batch_size, latent_size, loss_fn, opt_dis, opt_gen)`\n",
        "        3. `fit(discriminator, generator, epochs, train_dl, latent_size, loss_fn, opt_dis, opt_gen, save_gen_images_fn, generated_image_path)`\n",
        "\n",
        "* Utilities:\n",
        "    1. `save_model(model, saved_model_path, if_exists_stop)`\n",
        "    2. `save_gen_images(generator, path, denorm, batch_size, latent_size, index, images_name, nrows, print_info)`\n",
        "    3. `plot_decision_boundary(model, X, y)`"
      ],
      "metadata": {
        "id": "icK5ZR39MoVx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation: 1"
      ],
      "metadata": {
        "id": "q9IKQnGdUAGw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_dataset_zip(source: str, destination: str, if_exists_stop=False, delete_zip=True):\n",
        "    from pathlib import Path   # For creating the dataset directory\n",
        "    from shutil import rmtree  # For deleting the dataset directory if exists\n",
        "    import requests            # For geting the dataset from the `web`\n",
        "    import zipfile             # For extracting he dataset `zip` file\n",
        "    from os import remove      # For deleting the `zip` file\n",
        "\n",
        "\n",
        "    # Creating the Path object and getting the name of the `zip` file\n",
        "    dataset_path = Path(destination) / source.split('/')[-1].split('.')[0]\n",
        "    dataset_name_ext = source.split('/')[-1]\n",
        "\n",
        "    # If Path object exists then give the option to delete it or stop the execution\n",
        "    if dataset_path.is_dir():\n",
        "        print(f\"[INFO] `{dataset_path}` already exists...\")\n",
        "        \n",
        "        if if_exists_stop:\n",
        "            return\n",
        "\n",
        "        print(f\"[INFO] Deleting `{dataset_path}`..\")\n",
        "        rmtree(dataset_path)\n",
        "\n",
        "    # Creating the dataset directory\n",
        "    print(f\"[INFO] Creating `{dataset_path}`...\")\n",
        "    dataset_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Downloading the dataset inside the Path object\n",
        "    with open(dataset_path / dataset_name_ext, \"wb\") as f:\n",
        "        req = requests.get(source)\n",
        "\n",
        "        print(f\"[INFO] Downloading dataset: {source} to `{dataset_path}`...\")\n",
        "        f.write(req.content)\n",
        "\n",
        "    # Extracting the content of the `zip` file to destination\n",
        "    with zipfile.ZipFile(dataset_path / dataset_name_ext, \"r\") as zip_ref:\n",
        "        print(f\"[INFO] Unzipping dataset `{dataset_path / dataset_name_ext}` to `{dataset_path}`...\")\n",
        "        zip_ref.extractall(dataset_path)\n",
        "\n",
        "    # Deleting the `zip` file\n",
        "    if delete_zip:\n",
        "        print(f\"[INFO] Deleting `{dataset_path / dataset_name_ext}`...\")\n",
        "        remove(dataset_path / dataset_name_ext)\n",
        "\n",
        "    print(f\"[INFO] Dataset succesfully downloaded to `{dataset_path}`..\")\n",
        "\n",
        "    return dataset_path"
      ],
      "metadata": {
        "id": "a_vQEONvNTcw"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation: 2"
      ],
      "metadata": {
        "id": "T-5EWyfVegrf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_image(source, destination, if_exists_stop=False):\n",
        "    from pathlib import Path  # For creating the directory to store the image\n",
        "    import requests           # For downloading the image from the web\n",
        "    from os import remove     # For deleting the directory if exist\n",
        "\n",
        "\n",
        "    # Creating the Path object and getting the name of the image\n",
        "    image_path = Path('/'.join(destination.split('/')[:-1]))\n",
        "    image_name = destination.split('/')[-1]\n",
        "\n",
        "    # Overwriting the image if exists\n",
        "    if (image_path / image_name).is_file():\n",
        "        print(f\"[INFO] Image `{destination}` already exists...\")\n",
        "\n",
        "        if if_exists_stop:\n",
        "            return\n",
        "\n",
        "        print(f\"[INFO] Deleting `{destination}`...\")\n",
        "        remove(destination)\n",
        "    \n",
        "    # Creating the image directory if not exists\n",
        "    if not image_path.is_dir():\n",
        "        image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # Downloading the image from the web\n",
        "    with open(image_path / image_name, \"wb\") as f:\n",
        "        print(f\"[INFO] Downloading {source} to `{destination}`...\")\n",
        "        req = requests.get(source)\n",
        "        f.write(req.content)\n",
        "    \n",
        "    print(f\"[INFO] `{image_name}` succesfully downloaded to `{destination}`...\")"
      ],
      "metadata": {
        "id": "mON42-S8eiTF"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation: 3"
      ],
      "metadata": {
        "id": "Z9iWdTPdUSzd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_before_and_after(image_path_list, transforms):\n",
        "    from PIL import Image           # For opening the images and passing them to `pyplot`\n",
        "    import matplotlib.pyplot as plt # For displaying the images\n",
        "\n",
        "    # Formatting `pyplot` figure\n",
        "    plt.figure(figsize=(5, 3*len(image_path_list)))\n",
        "\n",
        "    i = 0\n",
        "    for image_path in image_path_list:\n",
        "\n",
        "        with Image.open(image_path) as img:\n",
        "            # Plotting the original image\n",
        "            i += 1\n",
        "            plt.subplot(len(image_path_list), 2, i)\n",
        "            plt.imshow(img)\n",
        "            plt.title(f\"Original Shape:\\n({img.size[0]}, {img.size[1]}, 3)\")\n",
        "            plt.axis(False)\n",
        "\n",
        "            # Plotting the transformed image\n",
        "            i += 1\n",
        "            transformed_img = transforms(img)\n",
        "            plt.subplot(len(image_path_list), 2, i)\n",
        "            plt.imshow(transformed_img.permute(1, 2, 0))\n",
        "            plt.title(f\"Transformed Shape:\\n({transformed_img.size(dim=0)}, {transformed_img.size(dim=1)}, {transformed_img.size(dim=2)})\")\n",
        "            plt.axis(False)\n",
        "\n",
        "            # Adding some padding for better display\n",
        "            plt.subplots_adjust(left=0.2, right=0.9)"
      ],
      "metadata": {
        "id": "02FAYR0aUUDN"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation: 4\n",
        "\n"
      ],
      "metadata": {
        "id": "NznbJyS9beMd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_dataset(dataset, split_prop=0.2, seed=9):\n",
        "    from torch.utils.data import random_split # For splitting the dataset\n",
        "    from torch import manual_seed             # For setting the random seed\n",
        "\n",
        "\n",
        "    length_1 = int(len(dataset) * split_prop) # desired length\n",
        "    length_2 = len(dataset) - length_1        # remaining length\n",
        "\n",
        "    print(\n",
        "        f\"[INFO] Splitting dataset of length {len(dataset)} into splits of size: \"\n",
        "        f\"{length_1} ({int(split_prop*100)}%), {length_2} ({int((1-split_prop)*100)}%)\"\n",
        "        )\n",
        "\n",
        "    # Creating splits using Pytorch's `random_split` with random seed\n",
        "    random_split_1, random_split_2 = random_split(dataset, [length_1, length_2], generator=manual_seed(seed))\n",
        "\n",
        "    return random_split_1, random_split_2"
      ],
      "metadata": {
        "id": "CQu46gqdb9p5"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Preparation: 5"
      ],
      "metadata": {
        "id": "KtX3QJ88o6xY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def show_images(images, denorm_fn, n_rows=3, fig_size=3):\n",
        "    from torchvision.utils import make_grid # For making the grid of images\n",
        "    import matplotlib.pyplot as plt         # For plotting the grid\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(fig_size, fig_size))\n",
        "    ax.set_xticks([]); ax.set_yticks([])\n",
        "    ax.imshow(make_grid(denorm_fn(images[:n_rows**2]).cpu(), nrow=n_rows).permute(1, 2, 0))"
      ],
      "metadata": {
        "id": "k3K-StCro8fe"
      },
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating: 1"
      ],
      "metadata": {
        "id": "m_IUNee6aFYA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_loss_curve(model_res, fig_size=(6, 4), font_size=11):\n",
        "    import matplotlib.pyplot as plt # For dispaying the curves\n",
        "\n",
        "\n",
        "    plt.figure(figsize=fig_size)\n",
        "    \n",
        "    plt.plot(range(model_res[\"model_epochs\"]), model_res[\"model_valid_loss\"], c='g', label=\"Valid Loss\")\n",
        "    plt.plot(range(model_res[\"model_epochs\"]), model_res[\"model_train_loss\"], c='b', label=\"Train Loss\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(f\"Loss Curves: {model_res['model_name']}\", fontsize=14)\n",
        "    plt.legend(fontsize=font_size)"
      ],
      "metadata": {
        "id": "bFSTdxUFcUYS"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating: 2"
      ],
      "metadata": {
        "id": "VnOx2vH0c759"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_acc_curve(model_res, fig_size=(6, 4), font_size=11):\n",
        "    import matplotlib.pyplot as plt # For dispaying the curves\n",
        "\n",
        "\n",
        "    plt.figure(figsize=fig_size)\n",
        "    \n",
        "    plt.plot(range(model_res[\"model_epochs\"]), model_res[\"model_valid_acc\"], c='g', label=\"Valid Accuracy (%)\")\n",
        "    plt.plot(range(model_res[\"model_epochs\"]), model_res[\"model_train_acc\"], c='b', label=\"Train Accuracy (%)\")\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(\"Accuracy (%)\")\n",
        "    plt.title(f\"Accuracy Curves: {model_res['model_name']} (%)\", fontsize=14)\n",
        "    plt.legend(fontsize=font_size)"
      ],
      "metadata": {
        "id": "lcCA1EPDc-KY"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating: 3\n"
      ],
      "metadata": {
        "id": "LZ1Cp916dp-q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image_predictions(model, class_names, image_path, transforms):\n",
        "    import torch\n",
        "    import matplotlib.pyplot as plt\n",
        "    from PIL import Image\n",
        "\n",
        "\n",
        "    # Setting the model's data type and device\n",
        "    model_dtype = next(model.parameters()).dtype\n",
        "    model_device = next(model.parameters()).device\n",
        "\n",
        "    # Converting the image to Tensor\n",
        "    with Image.open(image_path, \"r\") as img:\n",
        "        img_tensor = transforms(img)\n",
        "\n",
        "    # Making Predictions\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        logits = model(img_tensor.unsqueeze(dim=0).to(model_device))\n",
        "\n",
        "    pred_label = class_names[torch.softmax(logits, dim=1).argmax(dim=1)]\n",
        "    label_prob = torch.softmax(logits, dim=1).max().item() * 100\n",
        "\n",
        "    plt.imshow(img_tensor.permute(1, 2, 0).cpu())\n",
        "    plt.title(f\"Label: {pred_label} | Probability: {label_prob: .2f}%\")\n",
        "    plt.axis(False)"
      ],
      "metadata": {
        "id": "bknUnLRRdv1I"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating: 4"
      ],
      "metadata": {
        "id": "0w9LDFotnV3r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_writer(experiment_name, model_name, extras=None):\n",
        "    from torch.utils.tensorboard import SummaryWriter\n",
        "    from datetime import datetime\n",
        "    from os.path import join\n",
        "\n",
        "    # Loading and formating properly the current time\n",
        "    timestamp = datetime.now().strftime(\"%Y-%m-%d\")\n",
        "\n",
        "    # Creating the `log_dir` path\n",
        "    if extras:\n",
        "        log_dir = join(\"runs\", timestamp, experiment_name, model_name, extras)\n",
        "    else:\n",
        "        log_dir = join(\"runs\", timestamp, experiment_name, model_name)\n",
        "\n",
        "    print(f\"[INFO] SummaryWriter created, saving to: {log_dir}...\")\n",
        "    \n",
        "    return SummaryWriter(log_dir=log_dir)"
      ],
      "metadata": {
        "id": "_P5Dwec_nZKE"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluating: 5"
      ],
      "metadata": {
        "id": "5xyKkiNHtea8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_fn(model_logits, labels):\n",
        "    import torch\n",
        "    \n",
        "\n",
        "    labels_pred = torch.softmax(model_logits.type(torch.float32), dim=1).argmax(dim=1)\n",
        "    return (torch.sum(labels_pred == labels).item() / len(labels)) * 100"
      ],
      "metadata": {
        "id": "q_U_M5RTtf7c"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training: a1"
      ],
      "metadata": {
        "id": "nhf1Y7TjqKEL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def training_step(model, train_dl, loss_fn, eval_fn, opt):\n",
        "    from tqdm import tqdm # For the progress bar\n",
        "    \n",
        "\n",
        "    # Setting batch size and model's device\n",
        "    batch_size = train_dl.batch_size\n",
        "    model_device = next(model.parameters()).device\n",
        "\n",
        "    # Initialize training loss and accuracy\n",
        "    train_loss, train_eval = 0, 0\n",
        "\n",
        "    print(\"\\tTraining Step: \", end=\"\")\n",
        "\n",
        "    model.train()\n",
        "    for x_train, y_train in tqdm(train_dl):\n",
        "        # Moving batches to device\n",
        "        x_train, y_train = x_train.to(model_device, non_blocking=True), y_train.to(model_device, non_blocking=True)\n",
        "\n",
        "        # Generating predictions\n",
        "        model_logits = model(x_train)\n",
        "\n",
        "        # Calculate loss\n",
        "        loss = loss_fn(model_logits, y_train)\n",
        "        train_loss += loss.item()\n",
        "        train_eval += eval_fn(model_logits, y_train)\n",
        "\n",
        "        # Updating Model's parameters\n",
        "        opt.zero_grad()\n",
        "        loss.backward()\n",
        "        opt.step()\n",
        "\n",
        "    train_loss /= len(train_dl)\n",
        "    train_eval /= len(train_dl)\n",
        "\n",
        "    return train_loss, train_eval"
      ],
      "metadata": {
        "id": "tmFxKdpIqLT8"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training: a2"
      ],
      "metadata": {
        "id": "2CBrBcP-rE_a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validation_step(model, valid_dl, loss_fn, eval_fn):\n",
        "    import torch\n",
        "    from tqdm import tqdm\n",
        "\n",
        "    # Setting batch size and model's device\n",
        "    batch_size = valid_dl.batch_size\n",
        "    model_device = next(model.parameters()).device\n",
        "\n",
        "    # Initialize validation loss and accuracy\n",
        "    valid_loss, valid_eval = 0, 0\n",
        "\n",
        "    print(\"\\tValidation Step: \", end=\"\")\n",
        "\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for x_valid, y_valid in tqdm(valid_dl):\n",
        "            # Moving batches to model's device\n",
        "            x_valid, y_valid = x_valid.to(model_device, non_blocking=True), y_valid.to(model_device, non_blocking=True)\n",
        "\n",
        "            # Generate Predictions\n",
        "            model_logits = model(x_valid)\n",
        "\n",
        "            valid_loss += loss_fn(model_logits, y_valid).item()\n",
        "            valid_eval += eval_fn(model_logits, y_valid)\n",
        "\n",
        "        valid_loss /= len(valid_dl)\n",
        "        valid_eval /= len(valid_dl)\n",
        "\n",
        "        return valid_loss, valid_eval"
      ],
      "metadata": {
        "id": "wma1s_7KrGUC"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training: a3"
      ],
      "metadata": {
        "id": "hLPkKUSYr0oI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(model, epochs, train_dl, valid_dl, loss_fn, eval_fn, opt, writer=None):\n",
        "    from timeit import default_timer as timer\n",
        "    import torch\n",
        "\n",
        "\n",
        "    # Starting the `timer` and initialize the evaluating Lists\n",
        "    start_time = timer()\n",
        "    train_losses, train_evals = [], []\n",
        "    valid_losses, valid_evals = [], []\n",
        "\n",
        "    print(\"Starting Process...\\n\")\n",
        "    \n",
        "    for epoch in range(1, epochs + 1):\n",
        "        print(f\"-> Epoch: {epoch}/{epochs}\")\n",
        "\n",
        "        # Training and Evaluating the Model\n",
        "        train_loss, train_eval = training_step(model, train_dl, loss_fn, eval_fn, opt)\n",
        "        valid_loss, valid_eval = validation_step(model, valid_dl, loss_fn, eval_fn)\n",
        "\n",
        "        if (epoch == epochs):\n",
        "            print()\n",
        "        print()\n",
        "        print(\n",
        "            f\"   Train Loss: {train_loss:.4f} | \"\n",
        "            f\"Train Accuracy: {train_eval:.2f}% | \"\n",
        "            f\"Valid Loss: {valid_loss:.4f} | \"\n",
        "            f\"Valid Accuracy (%): {valid_eval:.2f}%\")\n",
        "        print(\"-\" * 99, end=\"\\n\\n\")\n",
        "        \n",
        "        train_losses.append(train_loss)\n",
        "        train_evals.append(train_eval)\n",
        "        valid_losses.append(valid_loss)\n",
        "        valid_evals.append(valid_eval)\n",
        "\n",
        "        # Tracking the experiment\n",
        "        if writer:\n",
        "            batch_size, n_channels, height, width = next(iter(train_dl))[0].shape\n",
        "\n",
        "            # Logging the Loss\n",
        "            writer.add_scalars(main_tag=\"Loss\",\n",
        "                              tag_scalar_dict={\"train_loss\": train_loss, \"valid_loss\": valid_loss},\n",
        "                              global_step=epoch)\n",
        "            # Logging the Evaluation Metric\n",
        "            writer.add_scalars(main_tag=\"Evaluation\",\n",
        "                              tag_scalar_dict={\"train_eval\": train_eval, \"valid_eval\": valid_eval},\n",
        "                              global_step=epoch)\n",
        "            # Tracking the Model Architecture\n",
        "            writer.add_graph(model=model,\n",
        "                             input_to_model=torch.randn(size=(batch_size, n_channels, height, width)).to(next(model.parameters()).device))\n",
        "            # Closing the `writer` object\n",
        "            writer.close()\n",
        "\n",
        "    print(\"Process Completed Successfully...\")\n",
        "\n",
        "    return {\"model_train_loss\": train_losses,\n",
        "        \"model_train_eval\": train_evals,\n",
        "        \"model_valid_loss\": valid_losses,\n",
        "        \"model_valid_eval\": valid_evals,\n",
        "        \"model_name\": model.__class__.__name__,\n",
        "        \"model_loss_fn\": loss_fn.__class__.__name__,\n",
        "        \"model_evaluating_m\": eval_fn.__name__,\n",
        "        \"model_optimizer\": opt.__class__.__name__,\n",
        "        \"model_device\": next(model.parameters()).device.type,\n",
        "        \"model_epochs\": epochs,\n",
        "        \"model_time\": timer() - start_time}"
      ],
      "metadata": {
        "id": "6exT47Mnr2O1"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training: b1"
      ],
      "metadata": {
        "id": "9qBVDQxRubHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_discriminator(discriminator, generator, real_image_batch, loss_fn, opt_dis, opt_gen, latent_size):\n",
        "    import torch\n",
        "\n",
        "\n",
        "    # Setting Devices, Batch Size and Latent\n",
        "    dis_device = next(discriminator.parameters()).device\n",
        "    gen_device = next(generator.parameters()).device\n",
        "\n",
        "    batch_size = real_image_batch.shape[0]\n",
        "    latent = torch.randn(size=(batch_size, latent_size, 1, 1))\n",
        "\n",
        "    # Setting Real and Fake Labels\n",
        "    real_labels = torch.ones(batch_size, 1, device=dis_device)\n",
        "    fake_labels = torch.zeros(batch_size, 1, device=dis_device)\n",
        "\n",
        "    # Calculating Loss and Score for Real Images\n",
        "    real_preds = discriminator(real_image_batch.to(dis_device))\n",
        "\n",
        "    real_loss = loss_fn(real_preds, real_labels)\n",
        "    real_score = torch.mean(real_preds).item()\n",
        "\n",
        "    # Calculating Loss and Score for Fake Images\n",
        "    fake_images = generator(latent.to(gen_device))\n",
        "\n",
        "    fake_preds = discriminator(fake_images.to(dis_device))\n",
        "\n",
        "    fake_loss = loss_fn(fake_preds, fake_labels)\n",
        "    fake_score = torch.mean(fake_preds).item()\n",
        "\n",
        "    # Updating Discriminator Parameters\n",
        "    loss = real_loss + fake_loss\n",
        "\n",
        "    opt_dis.zero_grad()\n",
        "    opt_gen.zero_grad()\n",
        "    loss.backward()\n",
        "    opt_dis.step()\n",
        "\n",
        "    return round(loss.item(), 4), round(real_score, 4), round(fake_score, 4)"
      ],
      "metadata": {
        "id": "SRBoRSxducZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training: b2"
      ],
      "metadata": {
        "id": "It6RS7A5uu7A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_generator(discriminator, generator, batch_size, latent_size, loss_fn, opt_dis, opt_gen):\n",
        "    import torch\n",
        "\n",
        "\n",
        "    # Setting Devices, Latent and Labels\n",
        "    dis_device = next(discriminator.parameters()).device\n",
        "    gen_device = next(generator.parameters()).device\n",
        "\n",
        "    latent = torch.randn(size=(batch_size, latent_size))\n",
        "\n",
        "    labels = torch.ones(batch_size, 1, device=dis_device)\n",
        "\n",
        "    # Generating Fake image and Calculating Loss\n",
        "    fake_image = generator(latent.to(gen_device))\n",
        "\n",
        "    fake_pred = discriminator(fake_image.to(dis_device))\n",
        "\n",
        "    loss = loss_fn(fake_pred, labels)\n",
        "\n",
        "    # Updating Generator Parameters\n",
        "    opt_dis.zero_grad()\n",
        "    opt_gen.zero_grad()\n",
        "    loss.backward()  \n",
        "    opt_gen.step()\n",
        "\n",
        "    return round(loss.item(), 4), fake_image"
      ],
      "metadata": {
        "id": "RkyJKE87uv9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training: b3"
      ],
      "metadata": {
        "id": "u_kUyzywu4v4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit(discriminator, generator, epochs, train_dl, latent_size, loss_fn, opt_dis, opt_gen, save_gen_images_fn=None, generated_image_path=None):\n",
        "    from timeit import default_timer as timer\n",
        "    from tqdm import tqdm\n",
        "\n",
        "\n",
        "    start_time = timer()\n",
        "\n",
        "    # Setting Evaluating Lists and Batch Size\n",
        "    dis_losses, gen_losses = [], []\n",
        "    real_scores, fake_scores = [], []\n",
        "\n",
        "    batch_size = train_dl.batch_size\n",
        "\n",
        "    i = 1\n",
        "    \n",
        "    print(\"Starting Process...\\n\")\n",
        "\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        print(f\"Epoch: {epoch} | Training: \", end=\"\")\n",
        "        for real_image_batch, _ in tqdm(train_dl):\n",
        "            \n",
        "            # Training the 2 models\n",
        "            dis_loss, real_score, fake_score = train_discriminator(discriminator,\n",
        "                                                                   generator,\n",
        "                                                                   real_image_batch,\n",
        "                                                                   loss_fn,\n",
        "                                                                   opt_dis,\n",
        "                                                                   opt_gen,\n",
        "                                                                   latent_size)\n",
        "            gen_loss, generated_image = train_generator(discriminator,\n",
        "                                                        generator,\n",
        "                                                        batch_size,\n",
        "                                                        latent_size,\n",
        "                                                        loss_fn,\n",
        "                                                        opt_dis,\n",
        "                                                        opt_gen)\n",
        "            \n",
        "        # Updating Evaluating Lists\n",
        "        dis_losses.append(dis_loss)\n",
        "        gen_losses.append(gen_loss)\n",
        "        real_scores.append(real_score)\n",
        "        fake_scores.append(fake_score)\n",
        "    \n",
        "        # Saving the Generated Image Batch\n",
        "        if save_gen_images_fn and generated_image_path:\n",
        "            save_gen_images_fn(generator, generated_image_path, batch_size, latent_size, i)\n",
        "            i += 1\n",
        "\n",
        "        # Printing Results\n",
        "        print(\n",
        "            f\"\\tDiscr_Loss: {dis_loss} | \"\n",
        "            f\"Gen_Loss: {gen_loss} | \"\n",
        "            f\"Real_Score: {real_score} | \"\n",
        "            f\"Fake_Score: {fake_score}\")\n",
        "        print('-' * 93, end=\"\\n\\n\")\n",
        "\n",
        "    print(\"Process Completed Succesfully...\")\n",
        "\n",
        "    return dis_losses, gen_losses, real_scores, fake_scores, (timer() - start_time)"
      ],
      "metadata": {
        "id": "oDAkRnU8u53l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilities: 1"
      ],
      "metadata": {
        "id": "N8RPsWlekrBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def save_model(model, saved_model_path: str, if_exists_stop=False):\n",
        "    from pathlib import Path\n",
        "    from torch import save\n",
        "    from os import remove\n",
        "\n",
        "\n",
        "    # Creating the Path object and getting the name of the model\n",
        "    target_path = Path('/'.join(saved_model_path.split('/')[:-1]))\n",
        "    model_name = saved_model_path.split('/')[-1]\n",
        "\n",
        "    # `model_name` should end with '.pt' or '.pth'\n",
        "    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\"), \"Wrong extension: Expecting `.pt` or `.pth`...\"\n",
        "    \n",
        "    # Creating the directory that the model is going to be saved if not exists\n",
        "    if not target_path.exists():\n",
        "        target_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    if (target_path / model_name).is_file():\n",
        "        print(f\"[INFO] Model `{model_name}` already exists on `{target_path}`...\")\n",
        "\n",
        "        if if_exists_stop:\n",
        "            return\n",
        "\n",
        "        print(f\"[INFO] Deleting `{target_path / model_name}`...\")\n",
        "        remove(target_path / model_name)\n",
        "\n",
        "    # Saving the Model to path\n",
        "    print(f\"[INFO] Saving Model `{model_name}` to `{target_path}`...\")\n",
        "    save(obj=model.state_dict(), f=target_path/model_name)\n",
        "\n",
        "    print(f\"[INFO] Model Successfully Saved to {target_path / model_name}\")"
      ],
      "metadata": {
        "id": "kRaGDoGxkuTg"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilities: 2"
      ],
      "metadata": {
        "id": "q-PLdsnMm7C1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a Function to Save a Grid of Images\n",
        "def save_gen_images(generator, path, denorm, batch_size, latent_size, index=0, images_name=\"generated_images\", nrows=10, print_info=False):\n",
        "    import torch\n",
        "    from torchvision.utils import save_image\n",
        "\n",
        "\n",
        "    generator.eval()\n",
        "    with torch.inference_mode():\n",
        "\n",
        "        # Creating latent and generating the images\n",
        "        latent = torch.randn(size=(batch_size, latent_size), device=next(generator.parameters()).device)\n",
        "        fake_images = generator(latent).reshape(batch_size, 1, 28, 28)\n",
        "        generated_image_grid_name = f\"{images_name}_{index:0=4d}.jpg\"\n",
        "    \n",
        "    if print_info:\n",
        "        print(f\"\\t[INFO] Saving {generated_image_grid_name} to {path}/\")\n",
        "\n",
        "    save_image(denorm(fake_images)[:nrows**2], path / generated_image_grid_name, nrow=nrows)\n",
        "\n",
        "    if print_info:\n",
        "        print(f\"\\t[INFO] {generated_image_grid_name} saved succesfully to {path}/\")"
      ],
      "metadata": {
        "id": "kkmBDpk6v-_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Utilities: 3"
      ],
      "metadata": {
        "id": "n2FrULFowoXF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_decision_boundary(model, X, y):\n",
        "    import torch\n",
        "    import numpy as np\n",
        "    import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "    \"\"\"\n",
        "    Plots decision boundaries of model predicting on X in comparison to y.\n",
        "    Source - https://madewithml.com/courses/foundations/neural-networks/ (with modifications)\n",
        "    \"\"\"\n",
        "    # Put everything to CPU (works better with NumPy + Matplotlib)\n",
        "    model.to(\"cpu\")\n",
        "    X, y = X.to(\"cpu\"), y.to(\"cpu\")\n",
        "\n",
        "    # Setup prediction boundaries and grid\n",
        "    x_min, x_max = X[:, 0].min() - 0.1, X[:, 0].max() + 0.1\n",
        "    y_min, y_max = X[:, 1].min() - 0.1, X[:, 1].max() + 0.1\n",
        "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, 101), np.linspace(y_min, y_max, 101))\n",
        "\n",
        "    # Make features\n",
        "    X_to_pred_on = torch.from_numpy(np.column_stack((xx.ravel(), yy.ravel()))).float()\n",
        "\n",
        "    # Make predictions\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        y_logits = model(X_to_pred_on)\n",
        "\n",
        "    # Test for multi-class or binary and adjust logits to prediction labels\n",
        "    if len(torch.unique(y)) > 2:\n",
        "        y_pred = torch.softmax(y_logits, dim=1).argmax(dim=1)  # mutli-class\n",
        "    else:\n",
        "        y_pred = torch.round(torch.sigmoid(y_logits))  # binary\n",
        "\n",
        "    # Reshape preds and plot\n",
        "    y_pred = y_pred.reshape(xx.shape).detach().numpy()\n",
        "    plt.contourf(xx, yy, y_pred, cmap=plt.cm.RdYlBu, alpha=0.7)\n",
        "    plt.scatter(X[:, 0], X[:, 1], c=y, s=40, cmap=plt.cm.RdYlBu)\n",
        "    plt.xlim(xx.min(), xx.max())\n",
        "    plt.ylim(yy.min(), yy.max())"
      ],
      "metadata": {
        "id": "Xy5OdhsOwqU4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}