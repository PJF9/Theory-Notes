{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## What `Going Modular` mean?\n",
        "\n",
        "We are going to turn a **Python Notebook** code into a series of Python's that offer similar functionalities.\n",
        "\n",
        "For example we could turn our notebook into a sereis of Python files:\n",
        "* `data_setup.py`: Download and prepare the data\n",
        "* `engine.py`: Define some training functions\n",
        "* `model.py`: Define the Model class\n",
        "* `train.py`: Train the Model\n",
        "* `utils.py`: Define some helpfull functions\n",
        "\n",
        "The format that out Project we would like to have is the following:\n",
        "```\n",
        "pytorch_project/\n",
        "├── pytorch_project/\n",
        "│   ├── data_setup.py\n",
        "│   ├── engine.py\n",
        "│   ├── model.py\n",
        "│   ├── train.py\n",
        "│   └── utils.py\n",
        "├── models/\n",
        "│   ├── model_1.pth\n",
        "│   └── model_2.pth\n",
        "└── data/\n",
        "    ├── data_folder_1/\n",
        "    └── data_folder_2/\n",
        "```"
      ],
      "metadata": {
        "id": "087HFes3XlqJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Why want to `Go Modular`?\n",
        "\n",
        "For large scale rojects creating and modifying Python files is must faster and eazier than having the entire Porject into a large Notebook.\n",
        "\n",
        "Some `pros` for going modular are:\n",
        "1. Controlling the version on dependencies\n",
        "2. Can package some code together to save rewritting\n",
        "3. No confusing text and images inside the code"
      ],
      "metadata": {
        "id": "ZOVvrGm1YjvP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Practice\n",
        "\n",
        "It's the best practice to _start_ the Project in a Notebook, understand the Data using Text and Images and then after having some knowledge of what you are going move the most usefull pieces of code to Python scripts. "
      ],
      "metadata": {
        "id": "ZUNSsXR8ZuFT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Script Mode\n",
        "\n",
        "**Script Mode** uses Jupyter's Notebook special commands to turn a cell into a Python Script. For example the bellow cell is creating a Python Script for printing \"Hello World\""
      ],
      "metadata": {
        "id": "y7RQcgGmb0gI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile hello_world.py\n",
        "\n",
        "print(\"Hello World\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F31-3bSYcWMG",
        "outputId": "65db12e8-bd10-4250-959b-0f2bf04b0f4d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing hello_world.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can run this file using:"
      ],
      "metadata": {
        "id": "wcdY5HWcceHW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python hello_world.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAPe2y0scgsC",
        "outputId": "17be1152-e49a-4085-dcb2-3282b4a955f5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As notice, the special command is `writefile`"
      ],
      "metadata": {
        "id": "5hj-YFBycngW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Folder for Storing the Python Scripts"
      ],
      "metadata": {
        "id": "aboOeI6Ad0Ut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os import makedirs\n",
        "\n",
        "# If the directory exists then it will leave it unharmed\n",
        "makedirs(\"going_modular\", exist_ok=True)"
      ],
      "metadata": {
        "id": "EYEHHpZNdz0k"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Folder to Store the Dataset"
      ],
      "metadata": {
        "id": "l4CPtuN1gldj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os import makedirs\n",
        "\n",
        "# If the directory exists then it will leave it unharmed\n",
        "makedirs(\"going_modular/data\", exist_ok=True)"
      ],
      "metadata": {
        "id": "DlV9fcVhgoKY"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Folder to Store the Python Scripts"
      ],
      "metadata": {
        "id": "bM3fitX9hwGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os import makedirs\n",
        "\n",
        "# If the directory exists then it will leave it unharmed\n",
        "makedirs(\"going_modular/going_modular\", exist_ok=True)"
      ],
      "metadata": {
        "id": "OsS4Wl7oh0OC"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating a Folder to Store the Models"
      ],
      "metadata": {
        "id": "zh4OaKkCEfqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os import makedirs\n",
        "\n",
        "# If the directory exists then it will leave it unharmed\n",
        "makedirs(\"going_modular/models\", exist_ok=True)"
      ],
      "metadata": {
        "id": "u6LnYzsUEiLa"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloading the Data"
      ],
      "metadata": {
        "id": "rxB41SNMeUk1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "from os import remove\n",
        "\n",
        "\n",
        "# Initializing the Path Object\n",
        "data_path = Path(\"/content/going_modular/data\")\n",
        "dataset_path = data_path / \"pizza_steak_sushi\"\n",
        "\n",
        "# If the Path Object doesn't exists we want to create it\n",
        "if dataset_path.is_dir():\n",
        "    print(f\"{dataset_path} already exists...\")\n",
        "else:\n",
        "    print(f\"{dataset_path} doesn't exists... Creating it...\")\n",
        "\n",
        "    dataset_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Downloading the Dataset\n",
        "with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
        "    req = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
        "\n",
        "    print(\"Downloading the Dataset...\")\n",
        "\n",
        "    f.write(req.content) # Downloads the content of the request to the specified folder\n",
        "\n",
        "# Unzipping the Dataset from Path\n",
        "with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
        "    print(\"Unzipping Dataset...\")\n",
        "    \n",
        "    zip_ref.extractall(dataset_path) # Extracting the `zip file` to Path\n",
        "\n",
        "# Deletting the `zip file`\n",
        "remove(data_path / \"pizza_steak_sushi.zip\")\n",
        "\n",
        "print(f\"Dataset Downloaded Successfully on {dataset_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Gx0ixnIeRke",
        "outputId": "8029c41e-eadb-4ebf-d35a-1d2ef135d3ac"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/going_modular/data/pizza_steak_sushi doesn't exists... Creating it...\n",
            "Downloading the Dataset...\n",
            "Unzipping Dataset...\n",
            "Dataset Downloaded Successfully on /content/going_modular/data/pizza_steak_sushi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting the Training and Testing Paths"
      ],
      "metadata": {
        "id": "O4KzrpKikfBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_path = dataset_path / \"train\"\n",
        "test_path = dataset_path / \"test\"\n",
        "\n",
        "print(train_path)\n",
        "print(test_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v9jE85cXkhmj",
        "outputId": "6c1c24c4-802c-492d-9ecf-c172c26e4755"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/going_modular/data/pizza_steak_sushi/train\n",
            "/content/going_modular/data/pizza_steak_sushi/test\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Dataset and Data Loader Instances (Python Script)"
      ],
      "metadata": {
        "id": "UZKBkH7dg6Nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/going_modular/data_setup.py\n",
        "from os import cpu_count\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Setting the Cores that will be used for the Data Loaders\n",
        "NUM_WORKERS = cpu_count()\n",
        "\n",
        "def create_dataloaders(train_dir: str, \n",
        "                       test_dir: str,\n",
        "                       train_transform: transforms.Compose,\n",
        "                       test_transform: transforms.Compose,\n",
        "                       batch_size: int,\n",
        "                       num_workers: int=NUM_WORKERS):\n",
        "\n",
        "    # Creating the Datasets using `ImageFolder`\n",
        "    train_ds = datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
        "    test_ds = datasets.ImageFolder(root=test_dir, transform=test_transform)\n",
        "\n",
        "    # Getting the labels from the Dataset\n",
        "    classes = train_ds.classes\n",
        "\n",
        "    # Turn the Datasets into Dataloaders using `DataLoader`\n",
        "    train_dl = DataLoader(dataset=train_ds,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True,\n",
        "                          num_workers=num_workers,\n",
        "                          pin_memory=True) # Speed thing up when we (during training) moving data from CPU to GPU\n",
        "    test_dl = DataLoader(dataset=test_ds,\n",
        "                         batch_size=batch_size,\n",
        "                         shuffle=False,\n",
        "                         num_workers=num_workers,\n",
        "                         pin_memory=True)\n",
        "    \n",
        "    # Returning the Dataloaders and Labels\n",
        "    return train_dl, test_dl, classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq6VcZHmhBAL",
        "outputId": "2e9693b5-7144-43d0-dca8-e200ad3df088"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/going_modular/data_setup.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Model (Python Script)"
      ],
      "metadata": {
        "id": "TzT8-YGCrNHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/going_modular/model.py\n",
        "import torch\n",
        "from torch import nn\n",
        "\n",
        "class TinyVGG(nn.Module):\n",
        "    def __init__(self, input_size, hidden_units, output_size):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv_block_1 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=input_size,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=(3, 3),\n",
        "                      stride=1,\n",
        "                      padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=(3, 3),\n",
        "                      stride=1,\n",
        "                      padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(2, 2),\n",
        "                         stride=2) # The default stride is the same as the kernel size\n",
        "        ) # Output: (`batch_size`, `hidde_units`, 30, 30)\n",
        "\n",
        "        self.conv_block_2 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=hidden_units,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=(3, 3),\n",
        "                      stride=1,\n",
        "                      padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(in_channels=hidden_units,\n",
        "                      out_channels=hidden_units,\n",
        "                      kernel_size=(3, 3),\n",
        "                      stride=1,\n",
        "                      padding=0),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size=(2, 2))\n",
        "        ) # Output: (`batch_size`, `hidde_units`, 13, 13)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(in_features=hidden_units*13*13, out_features=output_size),\n",
        "        ) # Output: (`batch_size`, `output_size`)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.classifier(self.conv_block_2(self.conv_block_1(x)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWW_OcW7rUrh",
        "outputId": "26f580a7-8768-402b-9cf8-60c227d83fbd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/going_modular/model.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating some Training and Evaluating Functions"
      ],
      "metadata": {
        "id": "QxmKvItOw6pz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/going_modular/engine.py\n",
        "import torch\n",
        "from tqdm.auto import tqdm\n",
        "from collections.abc import Callable\n",
        "from timeit  import default_timer as timer\n",
        "\n",
        "\n",
        "def accuracy_fn(model_logits, labels):\n",
        "    labels_pred = torch.softmax(model_logits.type(torch.float32), dim=1).argmax(dim=1)\n",
        "    return (torch.sum(labels_pred == labels).item() / len(labels)) * 100\n",
        "\n",
        "\n",
        "def training_step(model: torch.nn.Module,\n",
        "                  train_dl: torch.utils.data.DataLoader,\n",
        "                  loss_fn: torch.nn.Module,\n",
        "                  eval_metric: Callable[[torch.Tensor, torch.Tensor]],\n",
        "                  optim: torch.optim.Optimizer,\n",
        "                  n_batch_prints: int=None):\n",
        "    \n",
        "    batch_size = len(next(iter(train_dl))[0])\n",
        "    model_device = next(model.parameters()).device\n",
        "    train_loss, train_eval = 0, 0\n",
        "    dummy = False # For styling the output\n",
        "\n",
        "    model.train()\n",
        "    for batch_num, (x_train, y_train) in enumerate(train_dl, start=1):\n",
        "        # Moving Batches to Device\n",
        "        x_train, y_train = x_train.to(model_device), y_train.to(model_device)\n",
        "\n",
        "        model_logits = model(x_train)\n",
        "\n",
        "        loss = loss_fn(model_logits, y_train)\n",
        "        train_loss += loss.item()\n",
        "        train_eval += eval_metric(model_logits, y_train)\n",
        "\n",
        "        optim.zero_grad()\n",
        "        loss.backward()\n",
        "        optim.step()\n",
        "\n",
        "        if n_batch_prints and (batch_num % (len(train_dl) // n_batch_prints) == 0):\n",
        "            dummy = True\n",
        "            print(f\"\\tLooked at {batch_num*batch_size}/{len(train_dl)*batch_size} training samples...\")\n",
        "\n",
        "    train_loss /= len(train_dl)\n",
        "    train_eval /= len(train_dl)\n",
        "\n",
        "    if dummy:\n",
        "        print(\"-\" * 107)\n",
        "\n",
        "    return train_loss, train_eval\n",
        "\n",
        "\n",
        "def validation_step(model: torch.nn.Module,\n",
        "                    valid_dl: torch.utils.data.DataLoader,\n",
        "                    loss_fn: torch.nn.Module,\n",
        "                    eval_metric: Callable[[torch.Tensor, torch.Tensor]],\n",
        "                    n_batch_prints: int=None):\n",
        "    \n",
        "    batch_size = len(next(iter(valid_dl))[0])\n",
        "    model_device = next(model.parameters()).device\n",
        "    valid_loss, valid_eval = 0, 0\n",
        "    dummy = False # For styling the output\n",
        "\n",
        "    model.eval()\n",
        "    with torch.inference_mode():\n",
        "        for batch_num, (x_valid, y_valid) in enumerate(valid_dl, start=1):\n",
        "            # Moving Batches to Device\n",
        "            x_valid, y_valid = x_valid.to(model_device), y_valid.to(model_device)\n",
        "\n",
        "            model_logits = model(x_valid)\n",
        "\n",
        "            valid_loss += loss_fn(model_logits, y_valid).item()\n",
        "            valid_eval += eval_metric(model_logits, y_valid)\n",
        "\n",
        "            if n_batch_prints and (batch_num % (len(valid_dl) // n_batch_prints) == 0):\n",
        "                dummy = True\n",
        "                print(f\"\\tLooked at {batch_num*batch_size}/{len(valid_dl)*batch_size} validation samples...\")\n",
        "\n",
        "        valid_loss /= len(valid_dl)\n",
        "        valid_eval /= len(valid_dl)\n",
        "\n",
        "        if dummy:\n",
        "            print(\"-\" * 107)\n",
        "\n",
        "        return valid_loss, valid_eval\n",
        "\n",
        "\n",
        "def fit(model: torch.nn.Module,\n",
        "        epochs: int,\n",
        "        train_dl: torch.utils.data.DataLoader,\n",
        "        valid_dl: torch.utils.data.DataLoader,\n",
        "        loss_fn: torch.nn.Module,\n",
        "        eval_metric: Callable[[torch.Tensor, torch.Tensor]],\n",
        "        optim: torch.optim.Optimizer,\n",
        "        n_epoch_per_print: int=1,\n",
        "        n_train_batch_prints: int=None,\n",
        "        n_valid_batch_prints: int=None):\n",
        "    \n",
        "    start_time = timer()\n",
        "    train_losses, train_evals = [], []\n",
        "    valid_losses, valid_evals = [], []\n",
        "\n",
        "    print(\"Starting Process...\")\n",
        "    \n",
        "    for epoch in tqdm(range(1, epochs + 1)):\n",
        "        # Training Step\n",
        "        train_loss, train_eval = training_step(model, train_dl, loss_fn, eval_metric, optim, n_train_batch_prints)\n",
        "\n",
        "        # Validation Step\n",
        "        valid_loss, valid_eval = validation_step(model, valid_dl, loss_fn, eval_metric, n_valid_batch_prints)\n",
        "\n",
        "        if (n_epoch_per_print > 0) and (epoch % n_epoch_per_print == 0):\n",
        "            print(\n",
        "                f\"-> Epoch: {epoch} | \"\n",
        "                f\"Train Loss: {train_loss:.4f} | \"\n",
        "                f\"Train Accuracy: {train_eval:.2f}% | \"\n",
        "                f\"Test Loss: {valid_loss:.4f} | \"\n",
        "                f\"Test Evaluation (%): {valid_eval:.2f}%\")\n",
        "            print(\"-\" * 107)\n",
        "        \n",
        "        train_losses.append(train_loss)\n",
        "        train_evals.append(train_eval)\n",
        "        valid_losses.append(valid_loss)\n",
        "        valid_evals.append(valid_eval)\n",
        "\n",
        "    print(\"Process Completed Successfully...\")\n",
        "\n",
        "    return {\"model_train_loss\": train_losses,\n",
        "        \"model_train_eval\": train_evals,\n",
        "        \"model_valid_loss\": valid_losses,\n",
        "        \"model_valid_eval\": valid_evals,\n",
        "        \"model_name\": model.__class__.__name__,\n",
        "        \"model_loss_fn\": loss_fn.__class__.__name__,\n",
        "        \"model_evaluating_m\": eval_metric.__name__,\n",
        "        \"model_optimizer\": optim.__class__.__name__,\n",
        "        \"model_device\": next(model.parameters()).device.type,\n",
        "        \"model_epochs\": epochs,\n",
        "        \"model_time\": timer() - start_time}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dkl2xdUw_Hs",
        "outputId": "74002775-512f-4d3b-94b8-998411bf2075"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/going_modular/engine.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Function to Save the Model (Python Script)"
      ],
      "metadata": {
        "id": "89TgEZ7hCtY3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/going_modular/utils.py\n",
        "import torch\n",
        "from pathlib import Path\n",
        "\n",
        "def save_model(model: torch.nn.Module,\n",
        "               target_dir: str,\n",
        "               model_name: str):\n",
        "    \n",
        "    # Create the target Path Object\n",
        "    target_path = Path(target_dir)\n",
        "\n",
        "    # Creating the Directory\n",
        "    target_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    # `model_name` should end with '.pt' or '.pth'\n",
        "    assert model_name.endswith(\".pth\") or model_name.endswith(\".pt\")\n",
        "\n",
        "    # Create the Path Object for the saved model\n",
        "    save_model_path = target_path / model_name\n",
        "\n",
        "    print(f\"Saving Model to: {save_model_path}\")\n",
        "\n",
        "    # Save the model's `state_dict`\n",
        "    torch.save(obj=model.state_dict(),\n",
        "               f = save_model_path)\n",
        "\n",
        "    print(f\"Model Successfully Saved to: {save_model_path}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eBcvKffRCvZK",
        "outputId": "afe3f265-6905-4a5f-f5d6-c0b2b85aa716"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/going_modular/utils.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating Function to Train and Evaluate the Model (Python Script)"
      ],
      "metadata": {
        "id": "mHDqVvrTGQjl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile going_modular/going_modular/train.py\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "from torchvision import transforms\n",
        "import data_setup, model, engine, utils\n",
        "import os\n",
        "\n",
        "\n",
        "# Setting up Hyperparameters\n",
        "NUM_EPOCHS = 5\n",
        "BATCH_SIZE = 32\n",
        "HIDDEN_UNITS = 10\n",
        "LR = 1e-3\n",
        "\n",
        "# Seting up Directories\n",
        "train_dir = \"/content/going_modular/data/pizza_steak_sushi/train\"\n",
        "test_dir = \"/content/going_modular/data/pizza_steak_sushi/test\"\n",
        "\n",
        "# Setting up Device Agnostic Code\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Creating the Transformations\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "# Creating the DataLoaders using `data_setup.py`\n",
        "train_dl, test_dl, classes = data_setup.create_dataloaders(train_dir=train_dir,\n",
        "                                                            test_dir=test_dir,\n",
        "                                                            train_transform=train_transform,\n",
        "                                                            test_transform=test_transform,\n",
        "                                                            batch_size=BATCH_SIZE)\n",
        "\n",
        "# Creating the Model using `model.py`\n",
        "modelv0 = model.TinyVGG(input_size=3,\n",
        "                        hidden_units=HIDDEN_UNITS,\n",
        "                        output_size=len(classes)).to(device)\n",
        "\n",
        "# Setting up Loss Function and Optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "opt = optim.Adam(params=modelv0.parameters(), lr=LR)\n",
        "\n",
        "# Training and Evaluating the Model using `engine.py`\n",
        "res_0 = engine.fit(modelv0, NUM_EPOCHS, train_dl, test_dl, loss_fn, engine.accuracy_fn, opt)\n",
        "\n",
        "# Saving the Model using `utils.py`\n",
        "utils.save_model(model=modelv0,\n",
        "                 target_dir=\"/content/going_modular/models\",\n",
        "                 model_name=\"modelv0.pth\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBPwGA0gGSw1",
        "outputId": "0ff3e76b-0769-47a5-f796-403dd9c88fd5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing going_modular/going_modular/train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now our final directory structure looks like:\n",
        "```\n",
        "data/\n",
        "  pizza_steak_sushi/\n",
        "    train/\n",
        "      pizza/\n",
        "        train_image_01.jpeg\n",
        "        train_image_02.jpeg\n",
        "        ...\n",
        "      steak/\n",
        "      sushi/\n",
        "    test/\n",
        "      pizza/\n",
        "        test_image_01.jpeg\n",
        "        test_image_02.jpeg\n",
        "        ...\n",
        "      steak/\n",
        "      sushi/\n",
        "going_modular/\n",
        "  data_setup.py\n",
        "  engine.py\n",
        "  model_builder.py\n",
        "  train.py\n",
        "  utils.py\n",
        "models/\n",
        "  saved_model.pth\n",
        "```"
      ],
      "metadata": {
        "id": "wbZuTesXKkWB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Running the `train.py` Python Script"
      ],
      "metadata": {
        "id": "vZVBWJtiJVpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python going_modular/going_modular/train.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IPPjAHLrJcdg",
        "outputId": "dfae1743-dbe2-4645-9ac9-198f9c0946bb"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting Process...\n",
            "  0% 0/5 [00:00<?, ?it/s]-> Epoch: 1 | Train Loss: 1.1031 | Train Accuracy: 25.78% | Test Loss: 1.0960 | Test Evaluation (%): 39.96%\n",
            "-----------------------------------------------------------------------------------------------------------\n",
            " 20% 1/5 [00:03<00:15,  3.80s/it]-> Epoch: 2 | Train Loss: 1.0934 | Train Accuracy: 45.70% | Test Loss: 1.0988 | Test Evaluation (%): 26.04%\n",
            "-----------------------------------------------------------------------------------------------------------\n",
            " 40% 2/5 [00:07<00:10,  3.57s/it]-> Epoch: 3 | Train Loss: 1.1049 | Train Accuracy: 30.47% | Test Loss: 1.1063 | Test Evaluation (%): 27.08%\n",
            "-----------------------------------------------------------------------------------------------------------\n",
            " 60% 3/5 [00:10<00:06,  3.50s/it]-> Epoch: 4 | Train Loss: 1.0892 | Train Accuracy: 31.64% | Test Loss: 1.0765 | Test Evaluation (%): 31.25%\n",
            "-----------------------------------------------------------------------------------------------------------\n",
            " 80% 4/5 [00:16<00:04,  4.28s/it]-> Epoch: 5 | Train Loss: 1.0524 | Train Accuracy: 48.83% | Test Loss: 1.0757 | Test Evaluation (%): 27.08%\n",
            "-----------------------------------------------------------------------------------------------------------\n",
            "100% 5/5 [00:19<00:00,  3.88s/it]\n",
            "Process Completed Successfully...\n",
            "Saving Model to: /content/going_modular/models/modelv0.pth\n",
            "Model Successfully Saved to: /content/going_modular/models/modelv0.pth\n"
          ]
        }
      ]
    }
  ]
}