{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.9.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.6 64-bit"
    },
    "interpreter": {
      "hash": "765f0e6a717cdef1b96705705fe4f7f20bca40e4a56da864daf3394675fda3ca"
    },
    "colab": {
      "name": "global_temp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Importing Modules"
      ],
      "metadata": {
        "id": "Vb3-9jzR72s7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.optim as opt\r\n",
        "from torch.utils.data import DataLoader, random_split, TensorDataset\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "outputs": [],
      "metadata": {
        "id": "eh6c0XaG72s-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Taking a look at the Dataset"
      ],
      "metadata": {
        "id": "GqBJBUgj72tA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "df = pd.read_csv(\"global_temp.csv\")\r\n",
        "\r\n",
        "print(df.head(1))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           dt  ...  LandAndOceanAverageTemperatureUncertainty\n",
            "0  1750-01-01  ...                                        NaN\n",
            "\n",
            "[1 rows x 9 columns]\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdXgRKdx72tB",
        "outputId": "220ddaaf-a9c3-4cd2-e00a-50eee28bfe06"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fixing the data and creating the input and output tensor"
      ],
      "metadata": {
        "id": "Mn7vVnTR72tD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "numpy_dataset = np.genfromtxt(\"global_temp.csv\", delimiter=',')\r\n",
        "\r\n",
        "for i in range(len(df[\"dt\"])):\r\n",
        "    data_to_float = '.'.join(df[\"dt\"][i].split('-')[:-1])\r\n",
        "    numpy_dataset[i + 1][0] = data_to_float\r\n",
        "\r\n",
        "list_dataset_specific = []\r\n",
        "for rec in numpy_dataset[1:]:\r\n",
        "    if np.isnan(rec[1]):\r\n",
        "        rec[1] = 0\r\n",
        "    list_dataset_specific.append([rec[0], rec[1]])\r\n",
        "\r\n",
        "list_dataset_fixed = []\r\n",
        "temp = []\r\n",
        "j = 1753\r\n",
        "for i in range(len(list_dataset_specific[36:])):\r\n",
        "    if (i % 12 == 0) and (i != 0):\r\n",
        "        list_dataset_fixed.append([j] + temp)\r\n",
        "        j += 1\r\n",
        "        temp = []\r\n",
        "\r\n",
        "    temp.append(list_dataset_specific[36:][i][1])\r\n",
        "\r\n",
        "list_dataset_fixed.append(temp)\r\n",
        "\r\n",
        "inputs = []\r\n",
        "outputs = []\r\n",
        "for index in range(len(list_dataset_fixed)):\r\n",
        "    inputs.append(list_dataset_fixed[index][0])\r\n",
        "    outputs.append(np.average(list_dataset_fixed[index][2:]))\r\n",
        "\r\n",
        "inputs_tensor = torch.tensor(inputs, dtype=torch.float32)\r\n",
        "outputs_tensor = torch.tensor(outputs, dtype=torch.float32)"
      ],
      "outputs": [],
      "metadata": {
        "id": "_2uArXwv72tE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Hyperparameters"
      ],
      "metadata": {
        "id": "r-OD8PcN72tF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "batch_size = 32\r\n",
        "train_size = 173\r\n",
        "valid_size = 70\r\n",
        "test_size = 20\r\n",
        "\r\n",
        "input_size = 1\r\n",
        "output_size = 1\r\n",
        "\r\n",
        "h1_size = 10\r\n",
        "h2_size = 32\r\n",
        "h3_size = 64\r\n",
        "h4_size = 128\r\n",
        "h5_size = 100\r\n",
        "h6_size = 50\r\n",
        "h7_size = 10"
      ],
      "outputs": [],
      "metadata": {
        "id": "Rg6MZ4Tt72tG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the Dataloaders"
      ],
      "metadata": {
        "id": "ayylPvvE72tH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "train_ds, valid_ds, test_ds = random_split(TensorDataset(inputs_tensor, outputs_tensor), [train_size, valid_size, test_size])\r\n",
        "\r\n",
        "train_dl = DataLoader(train_ds, batch_size, num_workers=2, pin_memory=True, shuffle=True)\r\n",
        "valid_dl = DataLoader(valid_ds, batch_size, num_workers=2, pin_memory=True)"
      ],
      "outputs": [],
      "metadata": {
        "id": "eB2W9ylG72tJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Moving tensors to Device (cuda or cpu)"
      ],
      "metadata": {
        "id": "xZfZHe4q72tK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "source": [
        "class DeviceLoader:\r\n",
        "    def __init__(self, device, loader):\r\n",
        "        self.device = device\r\n",
        "        self.loader = loader\r\n",
        "\r\n",
        "    def __to_device(self, data):\r\n",
        "        if isinstance(data, (list, tuple)):\r\n",
        "            on_device_batch = [d.to(self.device, non_blocking=True) for d in data]\r\n",
        "            return on_device_batch\r\n",
        "        return data.to(self.device, non_blocking=True)\r\n",
        "\r\n",
        "    def __iter__(self):\r\n",
        "        for batch in self.loader:\r\n",
        "            yield self.__to_device(batch)\r\n",
        "\r\n",
        "    def __len__(self):\r\n",
        "        return len(self.loader)"
      ],
      "outputs": [],
      "metadata": {
        "id": "EeO17rHA72tL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the Model"
      ],
      "metadata": {
        "id": "-EhE00dk72tM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "source": [
        "class TemperatureModel(nn.Module):\r\n",
        "    def __init__(self, in_size, h1_size, h2_size, h3_size, h4_size, h5_size, h6_size, h7_size, out_size):\r\n",
        "        super().__init__()\r\n",
        "        self.linear1 = nn.Linear(in_size, h1_size)\r\n",
        "        self.linear2 = nn.Linear(h1_size, h2_size)\r\n",
        "        self.linear3 = nn.Linear(h2_size, h3_size)\r\n",
        "        self.linear4 = nn.Linear(h3_size, h4_size)\r\n",
        "        self.linear5 = nn.Linear(h4_size, h5_size)\r\n",
        "        self.linear6 = nn.Linear(h5_size, h6_size)\r\n",
        "        self.linear7 = nn.Linear(h6_size, h7_size)\r\n",
        "        self.linear8 = nn.Linear(h7_size, out_size)\r\n",
        "\r\n",
        "    def __call__(self, input_batch):\r\n",
        "        out1 = self.linear1(input_batch)\r\n",
        "        activation_out1 = F.relu(out1)\r\n",
        "        out2 = self.linear2(activation_out1)\r\n",
        "        activation_out2 = F.relu(out2)\r\n",
        "        out3 = self.linear3(activation_out2)\r\n",
        "        activation_out3 = F.relu(out3)\r\n",
        "        out4 = self.linear4(activation_out3)\r\n",
        "        activation_out4 = F.relu(out4)\r\n",
        "        out5 = self.linear5(activation_out4)\r\n",
        "        activation_out5 = F.relu(out5)\r\n",
        "        out6 = self.linear6(activation_out5)\r\n",
        "        activation_out6 = F.relu(out6)\r\n",
        "        out7 = self.linear7(activation_out6)\r\n",
        "        activation_out7 = F.relu(out7)\r\n",
        "        model_pred = self.linear8(activation_out7)\r\n",
        "        return model_pred\r\n",
        "\r\n",
        "    def __validation_step(self, validation_batch):\r\n",
        "        input_batch, output_batch = validation_batch\r\n",
        "        model_preds = self(input_batch)\r\n",
        "        loss = F.mse_loss(model_preds, output_batch)\r\n",
        "        acc = 100 - (torch.mean(torch.abs((output_batch - model_preds) / output_batch)) * 100)\r\n",
        "        return {\"valid_batch_loss\": torch.sqrt(loss).item(), \"valid_batch_acc\": acc}\r\n",
        "\r\n",
        "    def __validation_end(self, batch_results):\r\n",
        "        avg_loss = torch.tensor([x[\"valid_batch_loss\"] for x in batch_results]).mean().item()\r\n",
        "        avg_acc = torch.tensor([x[\"valid_batch_acc\"] for x in batch_results]).mean().item()\r\n",
        "        return {\"valid_loss\": avg_loss, \"valid_acc\": f\"{avg_acc}%\"}\r\n",
        "    \r\n",
        "    def training_step(self, training_batch):\r\n",
        "        input_batch, output_batch = training_batch\r\n",
        "        model_preds = self(input_batch)\r\n",
        "        loss = F.mse_loss(model_preds, output_batch)\r\n",
        "        return loss\r\n",
        "\r\n",
        "    def evaluate(self, validation_loader):\r\n",
        "        batch_results = [self.__validation_step(valid_batch) for valid_batch in validation_loader]\r\n",
        "        return self.__validation_end(batch_results)\r\n",
        "\r\n",
        "    def epoch_end(self, epoch, results):\r\n",
        "        return {\"Epoch: \": epoch+1, \"Loss: \": results[\"valid_loss\"], \"Acc:\": results[\"valid_acc\"]}\r\n",
        "\r\n",
        "    def predict(self, test_batch):\r\n",
        "        input_test, output_test = test_batch\r\n",
        "        preds = self(input_test.unsqueeze(dim=0))\r\n",
        "        loss = F.mse_loss(preds, output_test)\r\n",
        "        acc = 100 - torch.abs((output_test - preds) / output_test).item() * 100\r\n",
        "        return {\"Loss\": loss.sqrt().item(), \"Acc(%)\": acc, \"Actual\": output_test.item(), \"Predicted\": preds.item()}"
      ],
      "outputs": [],
      "metadata": {
        "id": "BrPqsk6k72tM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the model, the Device loaders and moving all the tensors to device"
      ],
      "metadata": {
        "id": "6PBM2nfN72tO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\r\n",
        "\r\n",
        "model = TemperatureModel(input_size, h1_size, h2_size, h3_size, h4_size, h5_size, h6_size, h7_size, output_size).to(device)\r\n",
        "\r\n",
        "train_loader = DeviceLoader(device, train_dl)\r\n",
        "valid_loader = DeviceLoader(device, valid_dl)\r\n",
        "test_loader = DeviceLoader(device, test_ds)"
      ],
      "outputs": [],
      "metadata": {
        "id": "Hfr1N2zL72tO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating the training loop"
      ],
      "metadata": {
        "id": "JN7Q9v7_72tO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "source": [
        "def fit(model, epochs, train_loader, valid_loader, opt_fn=opt.SGD, lr=1e-4):\r\n",
        "    history = []\r\n",
        "    optim = opt_fn(model.parameters(), lr=lr)\r\n",
        "    for epoch in range(epochs):\r\n",
        "        for training_batch in train_loader:\r\n",
        "            loss = model.training_step(training_batch)\r\n",
        "            loss.backward()\r\n",
        "            optim.step()\r\n",
        "            optim.zero_grad()\r\n",
        "\r\n",
        "        valid_results = model.evaluate(valid_loader)\r\n",
        "        epoch_results = model.epoch_end(epoch, valid_results)\r\n",
        "        history.append(epoch_results)\r\n",
        "        print(epoch_results)\r\n",
        "\r\n",
        "    return history"
      ],
      "outputs": [],
      "metadata": {
        "id": "Qdi8CM5K72tP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the Model"
      ],
      "metadata": {
        "id": "HDcJqkYq8swm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "source": [
        "history = fit(model, 10, train_loader, valid_loader)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:46: UserWarning: Using a target size (torch.Size([13])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Epoch: ': 1, 'Loss: ': 0.5886731147766113, 'Acc:': '94.85871124267578%'}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: UserWarning: Using a target size (torch.Size([6])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Epoch: ': 2, 'Loss: ': 1.037718653678894, 'Acc:': '89.76904296875%'}\n",
            "{'Epoch: ': 3, 'Loss: ': 1.8443384170532227, 'Acc:': '80.98458099365234%'}\n",
            "{'Epoch: ': 4, 'Loss: ': 0.6658509373664856, 'Acc:': '93.92556762695312%'}\n",
            "{'Epoch: ': 5, 'Loss: ': 0.6594939231872559, 'Acc:': '94.27777099609375%'}\n",
            "{'Epoch: ': 6, 'Loss: ': 0.8728339672088623, 'Acc:': '91.70928955078125%'}\n",
            "{'Epoch: ': 7, 'Loss: ': 0.8010405898094177, 'Acc:': '92.46492767333984%'}\n",
            "{'Epoch: ': 8, 'Loss: ': 0.7243301868438721, 'Acc:': '93.3253173828125%'}\n",
            "{'Epoch: ': 9, 'Loss: ': 0.722100555896759, 'Acc:': '93.58057403564453%'}\n",
            "{'Epoch: ': 10, 'Loss: ': 0.5895013213157654, 'Acc:': '94.8472900390625%'}\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjmzEMgU8qvC",
        "outputId": "9bff0035-bd98-4237-ebde-65375dbf3e43"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "source": [
        "for test_batch in test_loader:\r\n",
        "    print(model.predict(test_batch))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Loss': 0.16384410858154297, 'Acc(%)': 98.29337131232023, 'Actual': 9.600454330444336, 'Predicted': 9.764298439025879}\n",
            "{'Loss': 0.31287097930908203, 'Acc(%)': 96.56340219080448, 'Actual': 9.104090690612793, 'Predicted': 9.416961669921875}\n",
            "{'Loss': 0.43018627166748047, 'Acc(%)': 95.3815646469593, 'Actual': 9.314545631408691, 'Predicted': 9.744731903076172}\n",
            "{'Loss': 0.6377496719360352, 'Acc(%)': 92.69906803965569, 'Actual': 8.73518180847168, 'Predicted': 9.372931480407715}\n",
            "{'Loss': 0.5851249694824219, 'Acc(%)': 93.31931248307228, 'Actual': 8.758454322814941, 'Predicted': 9.343579292297363}\n",
            "{'Loss': 0.3897533416748047, 'Acc(%)': 95.65263278782368, 'Actual': 8.965272903442383, 'Predicted': 8.575519561767578}\n",
            "{'Loss': 1.2721834182739258, 'Acc(%)': 87.10703998804092, 'Actual': 9.86727237701416, 'Predicted': 8.595088958740234}\n",
            "{'Loss': 0.14517784118652344, 'Acc(%)': 98.34361262619495, 'Actual': 8.764727592468262, 'Predicted': 8.619549751281738}\n",
            "{'Loss': 0.6122369766235352, 'Acc(%)': 92.94058978557587, 'Actual': 8.672636032104492, 'Predicted': 9.284873008728027}\n",
            "{'Loss': 0.46345043182373047, 'Acc(%)': 94.90729086101055, 'Actual': 9.100273132324219, 'Predicted': 9.56372356414795}\n",
            "{'Loss': 0.8218317031860352, 'Acc(%)': 89.89792093634605, 'Actual': 8.135272979736328, 'Predicted': 8.957104682922363}\n",
            "{'Loss': 0.9287490844726562, 'Acc(%)': 88.79355937242508, 'Actual': 8.287636756896973, 'Predicted': 9.216385841369629}\n",
            "{'Loss': 0.35385608673095703, 'Acc(%)': 95.93319855630398, 'Actual': 8.701090812683105, 'Predicted': 9.054946899414062}\n",
            "{'Loss': 0.43929290771484375, 'Acc(%)': 94.90411691367626, 'Actual': 8.620545387268066, 'Predicted': 9.05983829498291}\n",
            "{'Loss': 0.44414424896240234, 'Acc(%)': 95.13649381697178, 'Actual': 9.132182121276855, 'Predicted': 8.688037872314453}\n",
            "{'Loss': 0.5307245254516602, 'Acc(%)': 94.1750779747963, 'Actual': 9.111272811889648, 'Predicted': 9.641997337341309}\n",
            "{'Loss': 0.3552732467651367, 'Acc(%)': 95.84617055952549, 'Actual': 8.552908897399902, 'Predicted': 8.908182144165039}\n",
            "{'Loss': 0.07565021514892578, 'Acc(%)': 99.19563056901097, 'Actual': 9.404909133911133, 'Predicted': 9.480559349060059}\n",
            "{'Loss': 0.4469575881958008, 'Acc(%)': 94.5570819079876, 'Actual': 8.211727142333984, 'Predicted': 8.658684730529785}\n",
            "{'Loss': 0.40779685974121094, 'Acc(%)': 95.23551166057587, 'Actual': 8.559090614318848, 'Predicted': 8.966887474060059}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:59: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
          ]
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ino7GOQG8-9H",
        "outputId": "bd807edb-d9ab-414f-9827-de5f8c44af20"
      }
    }
  ]
}