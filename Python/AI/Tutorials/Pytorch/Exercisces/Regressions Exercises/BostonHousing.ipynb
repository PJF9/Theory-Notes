{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fluid-rehabilitation",
   "metadata": {},
   "source": [
    "## Import the modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cardiac-popularity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as OPT\n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-modeling",
   "metadata": {},
   "source": [
    "## Taking a look at the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "impossible-reservation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD  TAX  \\\n",
       "0    0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900    1  296   \n",
       "1    0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671    2  242   \n",
       "2    0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671    2  242   \n",
       "3    0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622    3  222   \n",
       "4    0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622    3  222   \n",
       "..       ...   ...    ...   ...    ...    ...   ...     ...  ...  ...   \n",
       "501  0.06263   0.0  11.93   0.0  0.573  6.593  69.1  2.4786    1  273   \n",
       "502  0.04527   0.0  11.93   0.0  0.573  6.120  76.7  2.2875    1  273   \n",
       "503  0.06076   0.0  11.93   0.0  0.573  6.976  91.0  2.1675    1  273   \n",
       "504  0.10959   0.0  11.93   0.0  0.573  6.794  89.3  2.3889    1  273   \n",
       "505  0.04741   0.0  11.93   0.0  0.573  6.030   NaN  2.5050    1  273   \n",
       "\n",
       "     PTRATIO       B  LSTAT  MEDV  \n",
       "0       15.3  396.90   4.98  24.0  \n",
       "1       17.8  396.90   9.14  21.6  \n",
       "2       17.8  392.83   4.03  34.7  \n",
       "3       18.7  394.63   2.94  33.4  \n",
       "4       18.7  396.90    NaN  36.2  \n",
       "..       ...     ...    ...   ...  \n",
       "501     21.0  391.99    NaN  22.4  \n",
       "502     21.0  396.90   9.08  20.6  \n",
       "503     21.0  396.90   5.64  23.9  \n",
       "504     21.0  393.45   6.48  22.0  \n",
       "505     21.0  396.90   7.88  11.9  \n",
       "\n",
       "[506 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Datasets/HousingData.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42571ede",
   "metadata": {},
   "source": [
    "## Columns (Boston Housing Dataset):\n",
    "\n",
    "`CRIM`    : The crime rate per town.\n",
    "\n",
    "`ZN`      : The propotion of the residential zoned over 25.000 sq.ft.\n",
    "\n",
    "`INDUS`   : The propotion of non-retail business acres per town.\n",
    "\n",
    "`CHAS`    : Dummy variable.\n",
    "\n",
    "`NOX`     : The nitric oxides concentration (parts per 10 million).\n",
    "\n",
    "`RM`      : The average number of rooms per dwelling (ÎºÎ±Ï„Î¿Î¹ÎºÎ¹Î±)\n",
    "\n",
    "`AGE`     : The age of the resident.\n",
    "\n",
    "`DIS`     : The distances to five Boston employment centres.\n",
    "\n",
    "`RAD`     : The index of accessibility to highways.\n",
    "\n",
    "`TAX`     : The property-tax rate per 10,000(euro).\n",
    "\n",
    "`PTRATIO` : The student-teacher ratio by town.\n",
    "\n",
    "`B`       : The proportion of brown people by town.\n",
    "\n",
    "`LSTAT`   : The lower status of the population.\n",
    "\n",
    "`MEDV`    : Median value of owner-occupied homes in $1000's."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "random-optimization",
   "metadata": {},
   "source": [
    "## Replacing the NaN's values with the mean of each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "spectacular-workshop",
   "metadata": {},
   "outputs": [],
   "source": [
    "numpy_dataset = np.genfromtxt(\"../Datasets/HousingData.csv\", delimiter=',')\n",
    "\n",
    "mean_per_column = [0 for _ in range(14)]\n",
    "for row in numpy_dataset[1:]:\n",
    "    for i, column in enumerate(row):\n",
    "        if not np.isnan(column):\n",
    "            mean_per_column[i] += column\n",
    "\n",
    "mean_per_column = [x / (len(numpy_dataset) - 1) for x in mean_per_column]\n",
    "\n",
    "inputs = []\n",
    "outputs = []\n",
    "for row in numpy_dataset[1:]:\n",
    "    input_rec = []\n",
    "    output_rec = []\n",
    "    for i, column in enumerate(row):\n",
    "        if np.isnan(column):\n",
    "            row[i] = mean_per_column[i]\n",
    "            \n",
    "        if i != 13:\n",
    "            input_rec.append(row[i])\n",
    "        else:\n",
    "            output_rec.append(row[i])\n",
    "            \n",
    "    inputs.append(input_rec)\n",
    "    outputs.append(output_rec)\n",
    "    \n",
    "inputs = torch.tensor(inputs, dtype=torch.float32)\n",
    "outputs = torch.tensor(outputs, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "leading-nursing",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "colored-diagnosis",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 13\n",
    "hidden1_size = 32\n",
    "output_size = 1\n",
    "training_size = 350\n",
    "validation_size = 150\n",
    "test_size = 6\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-thursday",
   "metadata": {},
   "source": [
    "## Creating the Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unexpected-decimal",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds, valid_ds, test_ds = random_split(TensorDataset(inputs, outputs), [training_size, validation_size, test_size])\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "precise-bacteria",
   "metadata": {},
   "source": [
    "## Functions to move the Model into the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "careful-motion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device(\"cuda\")\n",
    "    return torch.device(\"cpu\")\n",
    "\n",
    "def to_device(data, device):\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(d, device) for d in data]\n",
    "    return data.to(device)\n",
    "\n",
    "class DeviceLoader:\n",
    "    def __init__(self, data_loader, device):\n",
    "        self.data_loader = data_loader\n",
    "        self.device = device\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for batch in self.data_loader:\n",
    "            yield to_device(batch, self.device)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "banner-baseball",
   "metadata": {},
   "source": [
    "## Moving the Data Loaders into the Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "expected-naples",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = get_default_device()\n",
    "\n",
    "train_loader = DeviceLoader(train_dl, device)\n",
    "valid_loader = DeviceLoader(valid_dl, device)\n",
    "test_loader = DeviceLoader(test_ds, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "israeli-instrumentation",
   "metadata": {},
   "source": [
    "## Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "oriental-resolution",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-05230787ade7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mHousingBoston\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0min_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh1_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0min_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh1_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinear2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh1_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class HousingBoston(nn.Module):\n",
    "    def __init__(self, in_size, h1_size, out_size):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(in_size, h1_size)\n",
    "        self.linear2 = nn.Linear(h1_size, out_size)\n",
    "        \n",
    "    def __call__(self, input_batch):\n",
    "        out1 = self.linear1(input_batch)\n",
    "        out1 = F.leaky_relu(out1)\n",
    "        out2 = self.linear2(out1)\n",
    "        out2 = F.leaky_relu(out2)\n",
    "        model_outputs = F.relu(out2)\n",
    "        return model_outputs\n",
    "    \n",
    "    def training_step(self, batch):\n",
    "        batch_inputs, batch_outputs = batch\n",
    "        model_outputs = self(batch_inputs)\n",
    "        loss = F.mse_loss(model_outputs, batch_outputs)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch):\n",
    "        batch_inputs, batch_outputs = batch\n",
    "        model_outputs = self(batch_inputs)\n",
    "        loss = F.mse_loss(model_outputs, batch_outputs)\n",
    "        return {\"valid_batch_loss\": torch.sqrt(loss).item()}\n",
    "    \n",
    "    def validation_end(self, results):\n",
    "        avg_loss = torch.tensor([x[\"valid_batch_loss\"] for x in results]).mean().item()\n",
    "        return {\"valid_loss\": avg_loss}\n",
    "    \n",
    "    def evaluate(self, val_loader):\n",
    "        valid_results = [self.validation_step(batch) for batch in val_loader]\n",
    "        return self.validation_end(valid_results)\n",
    "    \n",
    "    def epoch_end(self, epoch, results):\n",
    "        return {\"Epoch\": epoch+1, \"Loss\": results[\"valid_loss\"]}\n",
    "    \n",
    "    def predict(self, batch):\n",
    "        batch_inputs, batch_outputs = batch\n",
    "        model_outputs = self(batch_inputs)\n",
    "        loss = F.mse_loss(model_outputs, batch_outputs).sqrt()\n",
    "        return loss.item(), model_outputs.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "special-seating",
   "metadata": {},
   "source": [
    "## Creating the Model and moving it to the Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dominican-discount",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HousingBoston(\n",
       "  (linear1): Linear(in_features=13, out_features=32, bias=True)\n",
       "  (linear2): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = HousingBoston(input_size, hidden1_size, output_size)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "inside-blend",
   "metadata": {},
   "source": [
    "## Creating the training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "induced-filling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(model, epochs, train_loader, valid_loader, opt=OPT.SGD, lr=1e-4):\n",
    "    history = []\n",
    "    optimizer = opt(model.parameters(), lr=lr)\n",
    "    for epoch in range(epochs):\n",
    "        for train_batch in train_loader:\n",
    "            loss = model.training_step(train_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        valid_result = model.evaluate(valid_loader)\n",
    "        epoch_result = model.epoch_end(epoch, valid_result)\n",
    "        history.append(epoch_result)\n",
    "        \n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print({\"Epoch\": epoch+1, \"Loss\": valid_result[\"valid_loss\"]})\n",
    "            \n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "european-shanghai",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Epoch': 10, 'Loss': 8.974701881408691}\n",
      "{'Epoch': 20, 'Loss': 8.345569610595703}\n",
      "{'Epoch': 30, 'Loss': 8.159552574157715}\n",
      "{'Epoch': 40, 'Loss': 7.989112854003906}\n",
      "{'Epoch': 50, 'Loss': 7.897145748138428}\n",
      "{'Epoch': 60, 'Loss': 7.830381393432617}\n",
      "{'Epoch': 70, 'Loss': 7.720064163208008}\n",
      "{'Epoch': 80, 'Loss': 7.672008514404297}\n",
      "{'Epoch': 90, 'Loss': 7.629024505615234}\n",
      "{'Epoch': 100, 'Loss': 7.604162693023682}\n"
     ]
    }
   ],
   "source": [
    "history = fit(model, 100, train_loader, valid_loader, lr=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "silver-choice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs: 20.5, Predicted: 28.49228858947754, Loss: 7.992288589477539\n",
      "Outputs: 23.100000381469727, Predicted: 26.056379318237305, Loss: 2.956378936767578\n",
      "Outputs: 25.299999237060547, Predicted: 26.29618263244629, Loss: 0.9961833953857422\n",
      "Outputs: 14.899999618530273, Predicted: 10.933735847473145, Loss: 3.966263771057129\n",
      "Outputs: 13.800000190734863, Predicted: 17.56223487854004, Loss: 3.762234687805176\n",
      "Outputs: 8.300000190734863, Predicted: 19.230457305908203, Loss: 10.93045711517334\n"
     ]
    }
   ],
   "source": [
    "for batch in test_loader:\n",
    "    loss, outs = model.predict(batch)\n",
    "    print(f\"Outputs: {batch[1].item()}, Predicted: {outs}, Loss: {loss}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-cornwall",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
