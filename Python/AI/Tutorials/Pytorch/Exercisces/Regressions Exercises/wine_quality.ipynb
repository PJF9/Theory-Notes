{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.9.6",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.6 64-bit"
    },
    "interpreter": {
      "hash": "765f0e6a717cdef1b96705705fe4f7f20bca40e4a56da864daf3394675fda3ca"
    },
    "colab": {
      "name": "wine_quality.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ml0glxuJI9BU"
      },
      "source": [
        "### Importing the Core Modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKJv6VNsI9BY"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as opt\n",
        "from torch.utils.data import random_split, DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUPCfK8WI9Ba"
      },
      "source": [
        "### Taking a look at the Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JF03rLTRI9Bc",
        "outputId": "15298c7f-c4b2-4bb1-9c3f-27352c0cc796"
      },
      "source": [
        "np_dataset = np.genfromtxt(\"winequality-red.csv\", delimiter=';')\n",
        "print(np_dataset[:3])"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[    nan     nan     nan     nan     nan     nan     nan     nan     nan\n",
            "      nan     nan     nan]\n",
            " [ 7.4     0.7     0.      1.9     0.076  11.     34.      0.9978  3.51\n",
            "   0.56    9.4     5.    ]\n",
            " [ 7.8     0.88    0.      2.6     0.098  25.     67.      0.9968  3.2\n",
            "   0.68    9.8     5.    ]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x03kFvj5I9Be"
      },
      "source": [
        "### Creating the input and output tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97l59_aaI9Bf"
      },
      "source": [
        "inputs = []\n",
        "output = []\n",
        "\n",
        "for record in np_dataset[1:]:\n",
        "    inputs.append(record[:-1])\n",
        "    output.append(record[-1])\n",
        "\n",
        "inputs = torch.tensor(np.array(inputs).astype(np.float32))\n",
        "output = torch.tensor(np.array(output).astype(np.float32))"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqWJz35-I9Bg"
      },
      "source": [
        "### Initializing the Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "scYjnepyI9Bi"
      },
      "source": [
        "batch_size = 32\n",
        "train_size = 1_179\n",
        "valid_size = 400\n",
        "test_size = 20\n",
        "\n",
        "input_size = 11\n",
        "output_size = 1\n",
        "\n",
        "h1_size = 32\n",
        "h2_size = 64\n",
        "h3_size = 128\n",
        "h4_size = 256\n",
        "h5_size = 200\n",
        "h6_size = 150\n",
        "h7_size = 100\n",
        "h8_size = 50\n",
        "h9_size = 10"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTvK9NGgI9Bj"
      },
      "source": [
        "### Creating the Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCW2vJxdI9Bk"
      },
      "source": [
        "train_ds, valid_ds, test_ds = random_split(TensorDataset(inputs, output), [train_size, valid_size, test_size])\n",
        "\n",
        "train_dl = DataLoader(train_ds, batch_size, num_workers=2, pin_memory=True, shuffle=True)\n",
        "valid_dl = DataLoader(valid_ds, batch_size, num_workers=2, pin_memory=True)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9eGgrX0I9Bl"
      },
      "source": [
        "### Creating the class that will put all the data loaders on GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RabSND6wI9Bm"
      },
      "source": [
        "class DeviceLoader:\n",
        "    def __init__(self, device, loader):\n",
        "        self.device = device\n",
        "        self.loader = loader\n",
        "\n",
        "    def __to_device(self, data):\n",
        "        if isinstance(data, (list, tuple)):\n",
        "            on_device = [d.to(self.device, non_blocking=True) for d in data]\n",
        "            return on_device\n",
        "        return data.to(self.device, non_blocking=True)\n",
        "\n",
        "    def __iter__(self):\n",
        "        for batch in self.loader:\n",
        "            yield self.__to_device(batch)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbqLsk1fI9Bn"
      },
      "source": [
        "### Creating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_QwWrPSI9Bn"
      },
      "source": [
        "class WineModel(nn.Module):\n",
        "    def __init__(self, in_size, h1_size, h2_size, h3_size, h4_size, h5_size, h6_size, h7_size, h8_size, h9_size, out_size):\n",
        "        super().__init__()\n",
        "        self.linear1 = nn.Linear(in_size, h1_size)\n",
        "        self.linear2 = nn.Linear(h1_size, h2_size)\n",
        "        self.linear3 = nn.Linear(h2_size, h3_size)\n",
        "        self.linear4 = nn.Linear(h3_size, h4_size)\n",
        "        self.linear5 = nn.Linear(h4_size, h5_size)\n",
        "        self.linear6 = nn.Linear(h5_size, h6_size)\n",
        "        self.linear7 = nn.Linear(h6_size, h7_size)\n",
        "        self.linear8 = nn.Linear(h7_size, h8_size)\n",
        "        self.linear9 = nn.Linear(h8_size, h9_size)\n",
        "        self.linear10 = nn.Linear(h9_size, out_size)\n",
        "\n",
        "    def __call__(self, input_batch):\n",
        "        out1 = self.linear1(input_batch)\n",
        "        active_out1 = F.relu(out1)\n",
        "        out2 = self.linear2(active_out1)\n",
        "        active_out2 = F.leaky_relu(out2)\n",
        "        out3 = self.linear3(active_out2)\n",
        "        active_out3 = F.sigmoid(out3)\n",
        "        out4 = self.linear4(active_out3)\n",
        "        active_out4 = F.leaky_relu(out4)\n",
        "        out5 = self.linear5(active_out4)\n",
        "        active_out5 = F.sigmoid(out5)\n",
        "        out6 = self.linear6(active_out5)\n",
        "        active_out6 = F.leaky_relu(out6)\n",
        "        out7 = self.linear7(active_out6)\n",
        "        active_out7 = F.sigmoid(out7)\n",
        "        out8 = self.linear8(active_out7)\n",
        "        active_out8 = F.leaky_relu(out8)\n",
        "        out9 = self.linear9(active_out8)\n",
        "        active_out9 = F.relu(out9)\n",
        "        model_pred = self.linear10(active_out9)\n",
        "        return model_pred\n",
        "\n",
        "    def get_loss(self, batch):\n",
        "        inputs_batch, output_batch = batch\n",
        "        model_pred = self(inputs_batch)\n",
        "        loss = F.mse_loss(model_pred, output_batch)\n",
        "        return loss\n",
        "\n",
        "    def __get_acc(self, batch):\n",
        "        inputs_batch, output_batch = batch\n",
        "        model_pred = self(inputs_batch)\n",
        "        acc = 100 - (torch.mean(torch.abs((output_batch - model_pred) / output_batch)) * 100)\n",
        "        return acc\n",
        "\n",
        "    def __validation_step(self, valid_batch):\n",
        "        loss = self.get_loss(valid_batch)\n",
        "        acc = self.__get_acc(valid_batch)\n",
        "        return {\"valid_batch_loss\": torch.sqrt(loss).item(), \"valid_batch_acc\": acc}\n",
        "\n",
        "    def __validation_end(self, results):\n",
        "        avg_loss = torch.tensor([b[\"valid_batch_loss\"] for b in results]).mean().item()\n",
        "        avg_acc = torch.tensor([b[\"valid_batch_acc\"] for b in results]).mean().item()\n",
        "        return {\"valid_loss\": avg_loss, \"valid_acc\": avg_acc}\n",
        "\n",
        "    def evaluate(self, validation_loader):\n",
        "        batch_results = [self.__validation_step(b) for b in validation_loader]\n",
        "        return self.__validation_end(batch_results)\n",
        "\n",
        "    def epoch_end(self, epoch, valid_results):\n",
        "        return {\"Epoch\": epoch+1, \"Loss\": valid_results[\"valid_loss\"], \"Acc\": valid_results[\"valid_acc\"]}\n",
        "\n",
        "    def predict(self, test_rec):\n",
        "        inputs_test, output_test = test_rec\n",
        "        model_pred = self(inputs_test.unsqueeze(dim=0))\n",
        "        loss = F.mse_loss(model_pred, output_test)\n",
        "        acc = 100 - torch.abs((output_test - model_pred) / output_test).item() * 100\n",
        "        return {\"Loss\": loss.sqrt().item(), \"Acc(%)\": acc, \"Actual\": output_test.item(), \"Predicted\": model_pred.item()}"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrCr4nMDI9Bo"
      },
      "source": [
        "### Initializing the Model and moving all tenosrs to GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XgUw2J4I9Bp"
      },
      "source": [
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "model = WineModel(input_size, h1_size, h2_size, h3_size, h4_size, h5_size, h6_size, h7_size, h8_size, h9_size, output_size).to(device)\n",
        "\n",
        "train_loader = DeviceLoader(device, train_dl)\n",
        "valid_loader = DeviceLoader(device, valid_dl)\n",
        "test_loader = DeviceLoader(device, test_ds)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOWBEL1JI9Bp"
      },
      "source": [
        "### Creating the training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfW4Qk_OI9Bp"
      },
      "source": [
        "def fit(model, epochs, train_loader, valid_loader, opt_fn=opt.SGD, lr=1e-2):\n",
        "    history = []\n",
        "    optim = opt_fn(model.parameters(), lr=lr)\n",
        "    for epoch in range(epochs):\n",
        "        for training_batch in train_loader:\n",
        "            loss = model.get_loss(training_batch)\n",
        "            loss.backward()\n",
        "            optim.step()\n",
        "            optim.zero_grad()\n",
        "\n",
        "        valid_results = model.evaluate(valid_loader)\n",
        "        epoch_results = model.epoch_end(epoch, valid_results)\n",
        "        history.append(epoch_results)\n",
        "        print(epoch_results)\n",
        "\n",
        "    return history"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jx_3iAafI9Bp"
      },
      "source": [
        "### Training the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZ5VsmsvI9Bq",
        "outputId": "f9783bfc-55b5-4c64-8f22-a88e86d28278"
      },
      "source": [
        "history = fit(model, 10, train_loader, valid_loader)"
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: UserWarning: Using a target size (torch.Size([27])) that is different to the input size (torch.Size([27, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'Epoch': 1, 'Loss': 0.8486420512199402, 'Acc': 86.40647888183594}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: UserWarning: Using a target size (torch.Size([16])) that is different to the input size (torch.Size([16, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "{'Epoch': 2, 'Loss': 0.864513099193573, 'Acc': 86.17929077148438}\n",
            "{'Epoch': 3, 'Loss': 0.8788720369338989, 'Acc': 86.02088165283203}\n",
            "{'Epoch': 4, 'Loss': 0.8502781987190247, 'Acc': 87.3994140625}\n",
            "{'Epoch': 5, 'Loss': 1.0327157974243164, 'Acc': 83.10515594482422}\n",
            "{'Epoch': 6, 'Loss': 0.8362969756126404, 'Acc': 86.72574615478516}\n",
            "{'Epoch': 7, 'Loss': 0.9378591775894165, 'Acc': 88.22893524169922}\n",
            "{'Epoch': 8, 'Loss': 1.1026383638381958, 'Acc': 81.41567993164062}\n",
            "{'Epoch': 9, 'Loss': 0.8690319061279297, 'Acc': 86.12621307373047}\n",
            "{'Epoch': 10, 'Loss': 0.9260424971580505, 'Acc': 88.14601135253906}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KICKwvSwLkFx"
      },
      "source": [
        "### Predicting resutls"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhjlWubOLnN8",
        "outputId": "1ad06516-ad02-49cc-b8ca-4eec45b921b5"
      },
      "source": [
        "for t in test_loader:\n",
        "    print(model.predict(t))"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Loss': 0.8539590835571289, 'Acc(%)': 85.76734811067581, 'Actual': 6.0, 'Predicted': 5.146040916442871}\n",
            "{'Loss': 0.8536815643310547, 'Acc(%)': 85.77197343111038, 'Actual': 6.0, 'Predicted': 5.146318435668945}\n",
            "{'Loss': 0.8539900779724121, 'Acc(%)': 85.7668325304985, 'Actual': 6.0, 'Predicted': 5.146009922027588}\n",
            "{'Loss': 0.8535547256469727, 'Acc(%)': 85.77408790588379, 'Actual': 6.0, 'Predicted': 5.146445274353027}\n",
            "{'Loss': 0.1462407112121582, 'Acc(%)': 97.07518573850393, 'Actual': 5.0, 'Predicted': 5.146240711212158}\n",
            "{'Loss': 0.14629077911376953, 'Acc(%)': 97.0741843804717, 'Actual': 5.0, 'Predicted': 5.1462907791137695}\n",
            "{'Loss': 0.8536901473999023, 'Acc(%)': 85.77183037996292, 'Actual': 6.0, 'Predicted': 5.146309852600098}\n",
            "{'Loss': 0.14607715606689453, 'Acc(%)': 97.07845691591501, 'Actual': 5.0, 'Predicted': 5.1460771560668945}\n",
            "{'Loss': 0.853508472442627, 'Acc(%)': 85.77485829591751, 'Actual': 6.0, 'Predicted': 5.146491527557373}\n",
            "{'Loss': 0.8534760475158691, 'Acc(%)': 85.77539920806885, 'Actual': 6.0, 'Predicted': 5.146523952484131}\n",
            "{'Loss': 0.14626121520996094, 'Acc(%)': 97.07477577030659, 'Actual': 5.0, 'Predicted': 5.146261215209961}\n",
            "{'Loss': 0.8535704612731934, 'Acc(%)': 85.77382564544678, 'Actual': 6.0, 'Predicted': 5.146429538726807}\n",
            "{'Loss': 0.14621448516845703, 'Acc(%)': 97.07571025937796, 'Actual': 5.0, 'Predicted': 5.146214485168457}\n",
            "{'Loss': 0.8538589477539062, 'Acc(%)': 85.76901704072952, 'Actual': 6.0, 'Predicted': 5.146141052246094}\n",
            "{'Loss': 0.14607620239257812, 'Acc(%)': 97.07847591489553, 'Actual': 5.0, 'Predicted': 5.146076202392578}\n",
            "{'Loss': 0.1463489532470703, 'Acc(%)': 97.0730209723115, 'Actual': 5.0, 'Predicted': 5.14634895324707}\n",
            "{'Loss': 0.8534293174743652, 'Acc(%)': 85.77617853879929, 'Actual': 6.0, 'Predicted': 5.146570682525635}\n",
            "{'Loss': 0.853752613067627, 'Acc(%)': 85.77079027891159, 'Actual': 6.0, 'Predicted': 5.146247386932373}\n",
            "{'Loss': 0.14627599716186523, 'Acc(%)': 97.07447998225689, 'Actual': 5.0, 'Predicted': 5.146275997161865}\n",
            "{'Loss': 1.8536376953125, 'Acc(%)': 73.51946234703064, 'Actual': 7.0, 'Predicted': 5.1463623046875}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:69: UserWarning: Using a target size (torch.Size([])) that is different to the input size (torch.Size([1, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}